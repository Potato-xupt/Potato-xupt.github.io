<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL整体架构]]></title>
    <url>%2Fposts%2F10568%2F</url>
    <content type="text"><![CDATA[MySQL逻辑架构MySQL服务器逻辑架构图如图所示，MySQL的架构是三层架构，具体介绍如下： 最上层的服务（层）并不是MySQL独有的，大多数基于网络的客户端/服务器的工具或者服务都有类似的架构。这层的主要作用是连接处理、授权认证、安全等等。 第二层架构的是MySQL核心服务层，大多数MySQL的核心服务功能都在这一层，包括查询解析、分析、优化、缓存以及所有的内置函数，所有的跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。 第三层包括了存储引擎。存储引擎负责MySQL中数据的存储和提取。存储引擎不会去解析SQL（InnoDB例外，它会解析外键定义，因为MySQL服务器本身没有实现该功能），不同的存储引擎之间也不会相互通信，而只是简单地响应上层服务器的请求。 连接管理与安全性每个客户端都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个CPU核心或者CPU中运行。服务器会负责缓存线程，因此不需要为每一个新建的连接创建或者销毁线程。 当客户端连接到MySQL服务器时，服务器需要对其进行认证，认证基于用户名、原始主机信息和密码。 优化与执行MySQL会解析查询，并创建内部数据结构———解析树，然后对其进行各种优化，包括重写查询，决定表的读取顺序、以及选择合适的索引等。 用户可以通过特殊的关键字提示优化器，影响它的决策过程；也可以请求优化器解释优化过程的各个因素，使用户可以知道服务器是如何进行优化决策的，并提供一个参考基准，便于用户重构优化。 对于SELECT语句，在解析查询之前，服务器会先检查查询缓存，如果能在其中找到对应的查询，服务器就不必再执行查询解析、优化、和执行整个过程，而是直接返回查询缓存中的结果集。 并发控制这里讨论MySQL在两个层面的并发控制：服务器层和存储引擎层。 读写锁在处理并发或者写时，可以通过实现一个由两种类型的锁组成的锁系统来解决问题。这两种类型的锁通常被称为共享锁（shared lock）和排他锁（exclusive lock），也叫读锁（read lock）和写锁（write lock）。 读锁：是共享的，也就是相互不阻塞的。多个客户端在同一时刻可以同时读取同一个资源，而互不干扰。 写锁：是排他的，也就是一个写锁会阻塞其他的写锁和读锁，确保在给定的时间里，只有一个用户能执行写入，并防止其他用户读取正在写入的同一资源。 锁粒度一种提高共享资源并发性的方式就是让锁定对象更有选择性。尽量只锁定需要修改的部分数据，而不是所有的资源。更理想的方式是：只对会修改的数据片进行精确的锁定。下面是两种最重要的锁策略：表锁和行级锁。 表锁表锁（table lock）是MySQL中最基本的锁策略，并且是开销最小的策略：它会锁定整张表。 在特定场景表锁可能有良好的性能。另外，写锁也比读锁有更高的优先级，因此一个写锁请求可能会被插入到读锁列表的前面，反之读锁则不能插入到写锁的前面。 尽管存储引擎可以管理自己的锁，MySQL本身还是会使用各种有效的表锁来实现不同的目的。例如服务器会为ALTER TABLE之类的语句使用表锁，而忽略存储引擎的锁机制。 行级锁行级锁可以最大程度的支持并发，同时开销也最大。 行级锁只在存储引擎层实现，而MySQL服务层没有实现。 事务事务就是一组原子性的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功的对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。 可以同START TRANSACTION开始一个事务，然后要么用COMMIT提交事务将修改的数据持久保留，要么使用ROLLBACK撤销所有的修改。 数据库的特性有四条，简称为ACID，分别是：原子性（atomicity）、一致性（consistency）、隔离性（isolated）和持久性（durability）。 原子性（atomicity）：一个事务必须被视为一个不可分割的最小工作单元，整个事务操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中一部分操作，这就是事务的原子性。 一致性（consistency）：数据库总是从一个一致性的状态转换到另一个一致性的状态。 隔离性（isolated）：通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。这里的“通常来说”与隔离级别有关。 持久性（durability）：一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。 事务处理过程中额外的安全性，也会需要数据库系统做更多的额外工作。一个实现了ACID的数据库，相比没有实现ACID的数据库，通常会需要更强的CPU处理能力、更大的内存和更多的磁盘空间。 隔离级别在SQL标准中，定义了四种隔离级别。较低级别的隔离通常可以执行更高的并发，系统的开销也更低。 READ UNCOMMITED（未提交读）：在READ UNCOMMITTED级别，事务中的修改，即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也称为脏读（Dirty Read）。这个级别会导致很多问题，而从性能上来讲却并不会比其他级别好太多，但缺少其他级别的很多好处，在实际使用中很少使用。 READ COMMITTED（提交读）：大多数数据库系统的默认隔离级别都是READ COMMITTED（但MySQL不是）。这个级别满足隔离性。这个级别有时候也叫做不可重复读，因为两次执行同样的查询，可能会得到不一样的结果。 REPEATABLE READ（可重复读）：这一级别解决了脏读的问题，该级别保证了在同一个事务中多次读取同样记录的结果是一致的。但是理论上，可重复读级别还是无法结局幻读问题：当某个事务再次读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围内的记录时，会产生幻行。InnoDB和XtraDB存储引擎通过多版本并发控制（MVCC）解决了幻读问题。可重复读是MySQL的默认事务隔离级别。 SERIALIZABLE（可串行化）：这个级别是最高的隔离级别，通过强制事务串行执行，避免了幻读问题。即会再读取的每一行数据上都加上锁，所以可能导致大量的超时和锁争用问题，只要在非常需要确保数据一致性而且可以接受没有并发的情况下，才考虑使用该级别。 死锁死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。 为了解决这种问题，数据库实现了各种死锁检测和死锁超时机制。一种解决方式是当查询的时间达到锁等待超时的设定后放弃锁请求，这种方式通常来说不太友好。InnoDB目前处理死锁的方法是：将持有最少行级排他锁的事务进行回滚。 死锁产生有双重原因：有些是因为真正的数据冲突，但有些则完全由于存储引擎的实现方式导致的。死锁发生以后，只有部分或者完全回滚其中一个事务，才能打破死锁。 事务日志使用事务日志在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域的顺序I/O，所以采用事务日志的方式相对来说要快很多。 事务日志持久化以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。因此通常称之为预写式日志，修改数据需要写两次磁盘。 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改等数据。 MySQL中的事务MySQL提供了两种事务型的存储引擎：InnDB和NDB Cluster。另外还有一些第三方的存储引擎也支持事务，例如XtraDB和PBXT。 自动提交MySQL默认采用自动提交（AUTOCOMMIT）模式，也就是说，如果不是显式地开始一个事务，则每个查询都被当作一个事务执行提交操作。可以通过SET AUTOCOMMIT = ON/OFF来 开启/关闭 自动提交模式。 MySQL可以通过执行SET [GLOBAL | SESSION] TRANSATION ISOLATION LEVEL READ UNCOMMITTED| READ COMMITTED| REPEATABLE READ| SERIALIZABLE来设置全局/当前会话的隔离级别，新的隔离级别会在下一个事务开始的时候生效。 隐式和显式锁定InnoDB采用的是两阶段锁定协议。在执行过程中，随时都可以执行锁定，锁只有在执行COMMIT或者ROLLBACK的时候才会释放，并且所有的锁都是在同一时刻被释放。这就是隐式锁定。 InnoDB也支持通过特定的语句进行显式锁定：SELECT ... LOCK IN SHARE MODE 和 SELECT ... FOR UPDATE,MySQL也支持LOCK TABLES和UNLOCK TABLES语句，这是在服务层实现的，和存储引擎无关。 显示的使用这些语句不但没有必要，还会严重影响性能，实际上InnoDB的行级锁工作的更好，所以应当尽量避免使用LOCK TABLES。 多版本并发控制MySQL的大多数事务型存储引擎实现的都不是简单的行级锁，基于提升并发性能的考虑，它们一般都同时实现了多版本并发控制（MVCC）。可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有可能不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。 MVCC的实现是通过保存数据在某个时间点的快照来实现的。也就是说，不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。 InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间（或删除时间）。当然存储的不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。 SELECT：InnoDB会根据以下两个条件检查每行记录： InnoDB只查找早于当前事务版本的数据行（即行的系统版本号小于或等于事务的系统版本号），这样可以确保读取的行要么在事务开始前已经存在，要么是事务自身插入或者修改过的。 行的删除要么未定义，要么大于当前事务版本号。这样可以确保读取的行在事务开始之前未被删除。 INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号。 DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE：InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。 保存这两个额外系统版本号，优点就是使大多数读操作都可以不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行。缺点就是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。 MVCC只在 REPEATABLE READ（可重复读）和READ COMMITTED（提交读）两个隔离级别下工作，因为READ UNCOMMITTED总是读取最新的数据行，而SERIALIZABLE则会对所有读取的行加锁。 MySQL的存储引擎可以使用SHOW TABLE STATUS 命令显示表的相关信息。例如： 1234567891011121314151617181920212223mysql&gt; show table status like 'user' \G*************************** 1. row *************************** Name: user //表名 Engine: InnoDB //表引擎 Version: 10 //版本 Row_format: Dynamic//行的格式。Dynamic的行长度是可变的，一般包含可变长度的字段，如VARCHAR //；Fixed的行长度则是固定的，只包含固定长度的列，如CHAR。Compressed的行只在压缩 //表中存在。 Rows: 5 //表中的行数，MyISAM和其他一些存储引擎是精确值，但InnoDB是估计值。 Avg_row_length: 59 //平均每行包含的字节数 Data_length: 16384 //表数据的大小（字节）Max_data_length: 0 //表的最大数据容量，该值与存储引擎关 Index_length: 0 //索引的大小 Data_free: 0 //对于MyISAM表，表示已分配但目前没有使用的空间 Auto_increment: 6 //下一个AUTO_INCREMENT的值 Create_time: 2018-11-19 20:58:21 //表的创建时间 Update_time: NULL //表数据的最后修改时间 Check_time: NULL //使用CHECK TABLE命令或者myisamchk工具最后一次检查表的时间 Collation: utf8_general_ci //表的默认字符集和字符列排序规则 Checksum: NULL //如果启用，保存的是整个表的实时校验和 Create_options: //创建表时指定的其他选项 Comment: //建表时的备注1 row in set (0.00 sec) InnoDB存储引擎InnoDB是MySQL的默认事务型引擎，也是最重要、使用最广泛的存储引擎。它被设计用来处理大量的短期事务，短期事务大部分情况是正常提交的，很少会回滚。InnoDB的性能和自动崩溃恢复特性，使得它在非事务型存储的需求中也很流行。 InnoDB的数据存储在表空间长，表空间是由InnoDB管理的一个黑盒子，有一系列的数据文件组成，InnoDB可以将每个表的数据和索引存放在单独的文件中。 InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别，默认为REPATABLE READ，并且通过间隙锁（next-key locking）策略防止幻读的出现。间隙锁使得InnoDB不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。 InnoDB表是基于聚簇索引建立的，聚簇索引对主键查询有很高的性能，不过它的二级索引中必须包含主键列。因此若表上的索引较多的话，主键应当尽可能的小。InnoDB是平台独立的，可以将数据和索引文件在平台之间拷贝。 InnoDB内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建hash索引以及加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区等。 MyISAM存储引擎M有IASM是MySQL5.1之前的默认存储引擎。MyISAM提供了大量的特性，包括全文索引、压缩、空间函数等，但MyIASM不支持事务和行级锁，而且有一个最大的缺陷就是崩溃后无法安全恢复。 存储MyIASM会将表存储在两个文件中：数据文件和索引文件，分别以.MYD和.MYI为扩展名。MyIASM表可以包含动态或者静态行。MySQL会根据表的定义来决定采用何种行格式。MyIASM表可以存储的行记录数，一般受限于可用的磁盘空间，或者操作系统中单个文件的最大尺寸。 在MySQL5.0中，MyIASM表如果是可变行，则默认配置只能处理256TB的数据，可以通过修改表单MAX_ROWS和AVG_ROW_lENGTH选项的值来实现，两者相乘就是表可能达到的最大大小。修改这两个参数会导致重建整个表和表的所有索引，这可能需要很长的时间才能完成。 MyIASM特性 加锁与并发：MyIASM对整张表加锁，而不是针对行。读取时会对需要读到的表加共享锁，写入时则对表加排他锁。但是在表有读取查询的同时，也可以往表中插入新的记录（也被称为并发插入）。 修复：对于MyIASM表，MySQL可以手工或者自动检查和修复操作。执行表的修复可能导致一些数据的丢失，而且修复操作是非常慢的。可以通过CHECK TABLE mytable检查表的错误，如果有错误可以通过执行REPAIR TABLE mytable来修复，或者使用myiasmchk命令行工具也可以。 索引特性：对于MyIASM表，即使是BLOB和TEXT等长字段，也可以基于其前500个字符创建索引。MyIASM也支持全文索引，这是一种基于分词创建的索引。 延迟更新索引键（Delayed Key Write）：如果在创建MyIASM表时指定了DELAY_KEY_WRITE选项，在每次修改执行完时，不会立刻将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入到磁盘。这种方式可以极大的提升写入性能。 MyIASM压缩表如果表在创建并导入以后，不会再进行修改操作，那么这样得表更适合采用MyIASM压缩表。 可以使用myiaspack对MyIASM表进行压缩。压缩表是不能进行修改的（除非先将表解压、修改数据、然后再次压缩）。压缩表可以极大的减少磁盘空间占用，减少磁盘I/O，从而提升查询性能。压缩表也支持索引，但索引也是只读的。 MyIASM性能MyIASM引擎数据以紧密格式存储，所以在默写场景下的性能很好。 MyIASM有一些服务器级别的性能扩展限制，比如对索引键缓冲区的Mutex锁，MariaDB基于段的索引键缓冲区机制来避免该问题，性能上的表锁问题。 选择合适的引擎对于如何选择存储引擎，可以简单的归纳为一句话：除非需要用到某些InnoDB不具备的特性，并且没有其他办法可以代替，否则都应该优先选择InnoDB引擎。 除非万不得已，否则建议不要混合使用多种存储引擎，佛祖额可能带来一系列复杂的问题，以及一些潜在的bug和边界问题。 如果需要不同的存储引擎，应先考虑以下几个因素： 事务：如果应用到事务，那么InnoDB是目前最稳定并且经过沿着轨道选择。如果不需要事务，并且主要是SELECT和INSERT操作，那么MyISAM是不错的选择。 备份：如果需要在线热备份，那么选择InnoDB就是基本的要求。 崩溃恢复：建议选择InnoDB，因为拥有自动恢复功能。 特有的特性：有些应用可能依赖一些存储引擎所独有的特性或者优化，比如聚簇索引的优化，应该综合各种情况考虑，选择满足特殊情况下最优的引擎。 转换表的引擎转换表的引擎有三种方法： ALTER TABLE：将表从一个引擎修改为另一个引擎最简单的办法是使用ALTER TABLE语句。例如：ALTER TABLE mytable ENGINE = InnoDB。这种语法是用于任何存储引擎，但是有一个缺点：需要执行很长时间。MySQL会按照行将数据从原表复制到一张新的表，在复制期间可能会消耗系统所有的I/O能力，同时原表会加上锁。同时如果转换表的存储引擎，将会失去和引擎相关的所有特性. 导出与导入：可以使用mysqldump工具将数据导出到文件，然后修改文件中CREATE TABLE语句的存储引擎选项。 创建与查询：这种方法不需要导出整个表，而是先创建一个新的存储引擎的表，然后利用INSERT–SELECT语法来导数据。123CREATE TABLE innodb_table LIKE myisam_table;ALTER TABLE innodb_table ENGINE = InnoDB;INSERT INTO innodb_table (SELECT * FROM myisam_table); 当然如果数据量很大的情况下，可以采用分批导入的方法。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[类加载器]]></title>
    <url>%2Fposts%2F16040%2F</url>
    <content type="text"><![CDATA[类与类加载器对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。 上面这句话的意思即：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。 双亲委派模型从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。 以下是三种系统提供的主要的类加载器： 启动类加载器（Bootstrap ClassLoader）：这个类加载器负责将存放在\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 扩展类加载器（Extension ClassLoader）：这个加载器它负责加载\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）：由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器。一般情况下这个就是应用程序中默认的类加载器。 下图展示的类加载器之间的这种层次关系，称为类加载器的双亲委派模型。 双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应当有自己的父类加载器，这里类加载器之间的父子关系一般不会以继承的关系来实现，而是都使用组合关系来复用父加载器的代码。 双亲委派模型并不是一个强制性的约束模型，而是Java设计者推荐给开发者的一种类加载器实现方式。 每个类加载都有一个父类加载器，通过下面的程序来验证。 1234567public class ClassLoaderDemo &#123; public static void main(String[] args) &#123; System.out.println("ClassLodarDemo's ClassLoader is " + ClassLoaderDemo.class.getClassLoader()); System.out.println("The Parent of ClassLodarDemo's ClassLoader is " + ClassLoaderDemo.class.getClassLoader().getParent()); System.out.println("The GrandParent of ClassLodarDemo's ClassLoader is " + ClassLoaderDemo.class.getClassLoader().getParent().getParent()); &#125;&#125; 输出结果为： 123ClassLodarDemo's ClassLoader is sun.misc.Launcher$AppClassLoader@18b4aac2The Parent of ClassLodarDemo's ClassLoader is sun.misc.Launcher$ExtClassLoader@1b6d3586The GrandParent of ClassLodarDemo's ClassLoader is null 由结果可以看出AppClassLoader的父类加载器为ExtClassLoader，ExtClassLoader的类父加载器为null，但是null并不代表没有父类加载，而是BootstrapClassLoader。 双亲委派模型这里的双亲更多的表达的是“父母这一辈人而已，并不是说真的有一个Mother ClassLoader和一个Father ClassLoader”。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的类加载器中，只有当父类加载器反馈自己无法完成这个请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 双亲委派模型的源码实现如下： 123456789101112131415161718192021222324252627282930313233343536private final ClassLoader parent; protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先，检查请求的类是否已经被加载过 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123;//父加载器不为空，调用父加载器loadClass()方法处理 c = parent.loadClass(name, false); &#125; else &#123;//父加载器为空，使用启动类加载器 BootstrapClassLoader 加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //抛出异常说明父类加载器无法完成加载请求 &#125; if (c == null) &#123; long t1 = System.nanoTime(); //自己尝试加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 这个过程为：先检查是否已经被加载过，若没有加载则调用父加载器的loadClass()方法，若父加载器为空，则默认使用启动类加载器作为父加载器。如果父加载器加载失败，抛出ClassNotFoundException异常后，再调用自己的findClass()方法去加载。 双亲委派模型的好处：Java类锁着它的类加载器一起具备了一种带有优先级的层次关系，保证了Java程序的稳定运行，可以避免类的重复加载，同时也保证了Java的核心API不被篡改。 破坏双亲委派模型的三种方式： 我们可以自己定义一个类加载器，然后重载loadClass()即可。 Java设计团队引入的线程上下文类加载器（Thread Context ClassLoader）。这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果再应用程序的全部范围内都没有设置过的化，那这个类的加载器默认就是应用程序类加载器。 OSGi环境下的网状结构类加载过程。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机类加载过程]]></title>
    <url>%2Fposts%2F2708%2F</url>
    <content type="text"><![CDATA[虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 在Java语言里面，类型的加载、连接和初始化都是在程序运行期间完成的，这种策略虽然会令加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性。 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段，其中验证、准备、解析3个部分通称为连接。图中加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班的开始（而不是完成，因为通常会在一个阶段执行的过程中调用、激活另外一个阶段），而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。 对于初始化阶段，虚拟机规范严格指定了有且只有5种情况必须立即对类进行“初始化”： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令最常见的Java代码场景是：使用new关键字实例化对象、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外），以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包括main（）方法的那个类），虚拟机会先初始化这个主类。 当使用JDK1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 “有且只有”这5种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的场景例如： 通过子类引用父类的静态字段，不会导致子类初始化。 通过数组来定义引用类，不会触发此类的初始化。 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类。因此不会触发定义常量的类的初始化。 接口与类真正有所区别的是有且仅有需要开始初始化的5种场景中的第三种：当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部完成了初始化，只有在真正使用到父接口的时候才会初始化。 类加载的过程接下来详细讲解一下Java虚拟机中类加载的全过程，也就是加载、验证、准备、解析、初始化这5个阶段所执行的具体操作。 加载在加载阶段，虚拟机需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 虚拟机规范对上面这3点并不具体，因此是非常灵活的。比如：”通过全类名获取定义此类的二进制字节流” 并没有指明具体从哪里获取、怎样获取。比如：比较常见的就是从 ZIP 包中读取（日后出现的JAR、EAR、WAR格式的基础）、其他文件生成（典型应用就是JSP）等等。 一个非数组类的加载阶段（加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的，因为加载阶段既可以通过使用系统提供的引导类加载器来完成，也可以由用户自动移动类加载器去完成（即重写一个loadClass（）方法）。 对于数组类而言，数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的。一个数组类（称为C）的创建过程遵循以下规则： 如果数组的组件类型（即数组去掉一个维度的类型）是引用类型，那就递归采用本节中定义的加载过程去加载这个组件类型，数组C将在加载该组件类型的类加载器的类名称空间上被标识。 如果数组的组件类型不是引用类型（例如int[]数组）,Java虚拟机将会把数组C标记为与引导类加载器关联。 数组类的可见性与它的组件类型的可见性一致；如果数组的组件类型不是引用类型，那数组类的可见性将默认为public。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，然后再内存中实例化一个java.lang.Class类的对象。 加载阶段与连接阶段的部分内容（如一部分字节码文件格式验证动作）是交叉进行的。加载阶段尚未完成，连接阶段可能已经开始，在这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 验证验证这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 Java语言本身是相对安全的语言，但Class文件并不一定要求用Java源码编译而来，，在字节码层面上，有些Java代码无法做到的时区都是可能实现的，至少语义上可能表达出来。 对于虚拟机的类加载机制来说，验证阶段是一个非常重要的、但是不一定必要的阶段。如果运行的全部代码都已经被反复使用和验证过，那么在实施阶段就可以考虑使用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 验证阶段大致会完成下面4个阶段的校验工作：文件格式验证、元数据验证、字节码验证、符号引用验证。 文件格式验证第一阶段要验证字节流是否符合Class文件格式的规范，并且能够被当前版本的虚拟机处理。这一阶段可能包括验证是否以魔数0xCAFEBABE开头、主、次版本号是否在当前虚拟机处理范围之内等等。 该阶段的主要目的是为了保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。 元数据验证第二阶段是对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求。这个阶段可能包括但验证例如：这个类是否有父类、这个类的父类是否继承了不允许被继承的类等等。 这个阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证这阶段是整个验证过程中最复杂的一个阶段，主要目的是通过数据流和控制流分析，确定程序语义是合法的。在这个阶段对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件，例如：保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现在操作栈放置了一个int类型的数据，使用时却按long类型来加载入本地变量表等等。 在JDK1.6之后的javac编译器和Java虚拟机中进行了一项优化，给方法体的Code属性表中增加了一项名为“StackMapTable”的属性，这项属性描述了方法体中所有的基本快开始时本地变量表和操作栈应有的状态，在字节码验证期间，就不需要根据程序推导这些状态的合法性，只需检查StackMapTable属性中的记录是否合法即可，这样可以节省时间。 符号引用验证最后一个阶段的校验发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段（解析阶段）中发生。符号引用的目的是确保解析动作能正常执行。 准备准备阶段是正式为类变量（被static修饰的变量）分配内存并设置初始值的阶段，这些变量所使用的内存都将在方法区中进行分配，这阶段不包括实例变量，实例变量将会在对象实例化时随对象一起分配在Java堆中。 其次这里说的初始值通常情况下是数据类型的零值。假设一个类变量的定义为：public static int value = 123；，那变量value在准备阶段后的初始值是0而不是123，而赋值为123的指令putstatic被程序编译后，存放于类构造器方法中。 基本数据类型的零值： 相对于通常情况的特殊情况就是：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，例如public static final int value = 123;，在准备阶段会根据ConstantValue的设置将value赋值为123。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义的定位到目标即可。与虚拟机实现的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用：可以是直接指向目标的指针、相对偏移量或是一个能间件定位到目标的的句柄。和虚拟你实现的内存布局相关，引用到目标必定已经在内存中存在了。 虚拟机规范之中并未规定解析阶段发生的具体实现，只要求了在执行anewarray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invokespecial、invokestatic、invokevirtual、ldc、ldc_w、multianewarray、new、putfield和putstatic这16个用于操作符号引用的字节码指令之前，先对他们所使用的符号引用进行解析。所以虚拟机实现可以根据需要来判断到底是在类被加载器加载时就对常量池中的符号引用进行解析，还是等到一个符号引用将要被使用前才去解析它。 对同一个符号引用进行多次解析请求是很常见的事情，虚拟机可以对第一次解析的结果进行缓存，从而避免解析动作重复进行。 解析动作主要针对类、接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行，分别对应常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、CONSTANT_MethodHandle_info和CONSTANT_InvokeDynamic_info 7种常量类型。下面讲解前四种静态符号引用的过程。 类或接口的解析加色和当前代码所处的类为D，如果要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用，虚拟机解析过程如下三个步骤： 如果C不是一个数组类型，那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。在加载过程中，由于元数据验证、字节码验证的需要，又可能触发其他相关类的加载动作，例如加载这个类的父类或实现的接口。一旦这个加载过程出现了任何异常，解析过程就宣告失败。 如果C视野更数组类型，并且数组的元素类型为对象，，那将会按照第1步的规则加载数组的元素类型。 解析完成之前进行符号引用验证，确认D是否已具备对C的访问权限，如果不具备访问权限，将抛出IllegalAccessError异常。 字段解析首先将会对字段表内class_index项中索引的CONSTAN_Class_info符号引用进行解析，也就是字段所属的类或接口的符号引用。如果解析成功，拿奖这个字段所属的类或接口用C表示，后续解析步骤如下： 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，解析结束。 否则，如果在C中实现了接口，将会按照继承关系从下往上递归搜索各个接口和它的父接口，如果接口中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束。 否则，如果C不是java.lang.Object的话，将会按照继承关系从下往上递归搜索其父类，如果在父类中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段直接引用，查找失败。 否则查找失败，抛出NoSuchFieldError异常。 如果查找过程成功返回了引用，将会对这个字段进行权限验证，如果发现具备对字段的访问权限，将抛出IllegalAccessError异常。 如果有一个同名字段同时存在于C的接口和父类中，或者同时在自己或父类的多个接口中出现，那编译器将可能拒绝编译。 类方法解析类方法解析的第一个步骤与字段解析一样，也需要先解析出类方法表的class_index项中索引的方法所属的类或接口的符号引用，如果解析成功，用C表示这个类。后续步骤如下： 类方法和接口方法符号引用的常量类型定义是分开的，如果在类方法表中发现class_index中索引的C是个接口，那就直接抛出java.lang.IncompatibleClassChangeError异常。 如果通过了第1步，在类C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。 否则，在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。 否则，在类C实现的接口列表及他们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果存在匹配的方法，说明类C是一个抽象，这时查找结束，抛出java.lang.AbstractMethodError异常。 否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError。 最后，如果查找过程成功返回了直接引用，将会对这个方法进行权限验证，如果发现不具备对此方法的访问权限，将抛出java.lang.IllegalAccessError异常。 接口方法解析接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用，如果解析成功，依然用C表示这个接口，接下来虚拟机将会按照如下步骤进行后续的接口方法搜索。 与类方法解析不同，如果在接口方法表中发现class_index中的索引C是个类而不是接口，那就直接抛出java.lang.IncompatibleClassChangeError异常。 否则，在接口C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。 否则，在接口C的父接口中递归查找，直到java.lang.Object（查找范围会包括Object类）为止，看是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。 否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError异常。 由于接口中的所有方法默认都是public，所以不存在访问权限的问题，因此接口方法的符号解析应当不会抛出java.lang.IllegalAccessError异常。 初始化到了初始化阶段，才真正开始执行类中定义的Java程序代码（或者说字节码）。也可以说初始化阶段是执行类的方法的过程。 方法是由编译器自动收集类中的所有类变量的复制动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量；定义i在它之后的变量，在前面的静态语句块可以赋值，但是不能访问。 方法不许需要显式的调用父类的构造器，虚拟机会保证在子类的方法执行之前，父类的方法已经执行完毕。因此在虚拟机中第一个被执行的方法的类肯定是java.lang.Object。 由于父类的方法先执行，因此父类中定义的静态语句块要优先于子类的变量赋值操作。 方法对于类或接口来说不是必须的，一个类中没有没有静态语句块，也没有对变量的赋值操作，那么编译器就可以不为这个类生成方法。 接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此也会生出方法。但是与类不同，执行接口的方法不需要先执行父接口的方法，只有当父接口中定义的变量使用时，父接口才会被初始化，接口的实现类在初始化时也一样不会执行接口的方法。 虚拟机会保证一个类的方法在多线程环境中被正确的加锁、同步。如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的方法，其他线程都需要阻塞等待，直到活动线程执行方法完毕。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类文件结构]]></title>
    <url>%2Fposts%2F31580%2F</url>
    <content type="text"><![CDATA[Java虚拟机不和包括Java在内的任何语言绑定，它只与“Class”文件这种特定的二进制文件格式所关联，Class文件中包含了Java虚拟机指令集和符号表以及若干其他辅助信息。 可以说Class文件是不同的语言在Java虚拟机之间的重要桥梁，同时也是支持Java跨平台很重要的一个原因。 Class类文件结构总览Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格地按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符，当遇到需要占用8位字节以上空间的数据项时，则会按照高位在前的方式分割成若干个8位子节进行存储。 任何一个Class文件都对应着唯一一个类或接口的定义信息，但反过来说，类或接口并不一定都得定义在文件里（譬如类或接口也可以通过类加载器直接生成）。 Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：无符号数和表。 无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所以表都习惯性地以”_info”结尾，表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。 Class文件格式： 12345678910111213141516u4 magic; //Class 文件的标志u2 minor_version; //Class 的小版本号u2 major_version; //Class 的大版本号u2 constant_pool_count; //常量池的数量cp_info constant_pool[constant_pool_count-1]; //常量池u2 access_flags; //Class 的访问标志u2 this_class; //当前类u2 super_class; //父类u2 interfaces_count; //接口u2 interfaces[interfaces_count]; //一个类可以实现多个接口u2 fields_count; //Class 文件的字段属性field_info fields[fields_count]; //一个类会可以有个字段u2 methods_count; //Class 文件的方法数量method_info methods[methods_count]; //一个类可以有个多个方法u2 attributes_count; //此类的属性表中的属性数attribute_info attributes[attributes_count]; //属性表集合 无论是无符号数还是表，当需要描述同一类型数据但数量不定时，经常会使用一个潜质的容量计数器加若干个连续的数据项形式，这时称这一系列的某一类型的数据为某一类型的集合。 Class文件字节码结构组织示意图： 魔数每个Class文件的头4个字节称为魔数（Magic Number），它的唯一作用就是确定这个文件是否为一个能被虚拟机接受到Class文件，很多文件存储标准中都使用魔数来进行身份识别而不是扩展名的主要原因是基于安全方面的考虑，因为文件扩展名可以随意的改动。 1u4 magic; //Class 文件的标志 Java中Class文件的魔数值为：0xCAFEBABE（咖啡宝贝？）。 Class文件版本紧接着魔术的4个字节存储的是Class文件的版本号：第5个和第6个是次版本号（Minor Version），第7个和第8个是主版本号（Major Version）。 12u2 minor_version; //Class 的次版本号u2 major_version; //Class 的主版本号 Java版本号是从45开始的，JDK1.1之后每个JDK大版本发布主版本号向上加一，高版本的JDK能向下兼容以前版本的Class文件，但不能运行以后版本的Class文件，即使文件格式并未发生任何变化。 常量池紧接着主次版本号之后的是常量池入口，常量池可以理解为Class文件之中的资源仓库，它是Class文件结构中与其他项目关联最多的数据类型，也是战役Class文件空间最大的数据项目之一，同时它还是在Class文件中第一个出现的表类型数据项目。 12u2 constant_pool_count; //常量池的数量cp_info constant_pool[constant_pool_count-1]; //常量池 常量池的入口为一项u2类型的数据，代表常量池容量计数值（constant_pool_count），这个容量计数是从1开始而不是从0开始的，值为0代表“不引用任何一个常量池项目”的特殊情况。Class文件结构中只有常量池的容量计数是从1开始的。 常量池中主要存放两大类常量：字面量和符号引用。字面量比较接近于Java语言层面的常量概念，如文本字符串、声明为final类型的常量值等；而符号引用则属于编译原理方面的概念，包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 在Class文件之不会保存各个方法、字段的最终内存的布局信息，当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址之中。 常量池中每一个项都是一个表，这14种表有一个共同的特点：表开始的第一位是一个u1类型的标志位（tag），代表这个常量属于哪种常量类型。 由于Class文件中方法、字段等都需要引用CONSTANT_Utf8_info型常量来描述名称，而这里的最大长度就是length的最大值，既u2类型能表达的最大值65535，所以Java程序中如果定义可超过64KB英文字符的变量或方法名，将会无法编译。 Class 文件可以通过javap -v class类名 指令来看一下其常量池中的信息(javap -v class类名-&gt; temp.txt ：将结果输出到 temp.txt 文件)。 常量池中一部分自动生成的常量的确都没有在Java代码里面出现过，但它们会被后面即将讲到的字段表（field_info）、方法表（method_info）、属性表（attribute_info）引用到，他们会用来描述一些不方便使用“固定字节”进行表达的内容，譬如描述方法的返回值是什么？有几个参数？每个参数的类型是什么？ 常量池中的14种常量项的结构总表： 访问标志在常量池结束之后，紧接着的两个字节代表访问标志（access_flags），这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是接口还是类；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否声明为final等。 1u2 access_flags; //Class 的访问标记 最后这两个字节的值是上面这8个标志位的值的异或结果，没有用到的标志位一律为0。 类索引、父类索引与接口索引集合类索引和父类索引都是一个u2类型的数据，而接口索引集合是一组u2类型的数据的集合，Class文件中由这三项来确定这个类的继承关系。 1234u2 this_class; //当前类u2 super_class; //父类u2 interfaces_count; //接口u2 interfaces[interfaces_count]; //一个类可以实现多个接口 类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。除了Java.lang.Object之外，所有的Java类都有父类，因此除了Java.lang.Object之外，所有Java类的父类索引都不为0， 接口索引集合就用来描述这个类实现了哪些接口，这些实现的接口将按implements语句（如果这个类本身是一个接口，则应当是extends语句）后的接口顺序从左到右排列在接口索引集合中。 类索引、父类索引和接口索引集合都按顺序排列在访问标志之后；对于接口索引集合，入口的第一项————u2类型的数据为接口计数器，表示索引表的容量，如果该类没有实现任何接口，则该计数器值为0。 字段表集合字段表（field_info）用于描述接口或者类中声明的变量。字段包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。 12u2 fields_count; //Class 文件的字段的个数field_info fields[fields_count]; //一个类会可以有个字段 字段表的结构： 字段修饰符放在access_flags项目中，在实际情况中，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED三个标志最多只能选择其一，ACC_FINAL、ACC_VOLATILE不能同时选择，接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志，其可以设置的标志位和含义如图： 跟随access_flags标志的是两项索引值：name和descriptor_index。它们都是对常量池的引用，分别代表着字段的简单名称以及字段和方法的描述符。 全限定名：一个类的全名的“.”全部替换成“/”简单名称：没有类型和参数修饰的方法或字段名称，既只有名字描述符：用来描述字段的数据类型、方法的参数列表（包括数量、类型和顺序）和返回值。描述符标识字符含义：对于数组来说，每一维度将使用一个前置的“[”字符来描述；描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“（）”内 descriptor_index之后跟随着一个属性表集合用于存储一些额外的信息，字段都可以在描述表中描述零至多项的额外信息。 字段表集合中不会列出从超累或者父类中继承来的字段，但有可能列出原本Java代码之中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。另外如果两个字段的描述符不一致，那字段重名就是合法的。 方法表集合方法表的结构如同字段表一样： 12u2 methods_count; //Class 文件的方法的数量method_info methods[methods_count]; //一个类可以有个多个方法 方法表的 access_flag 取值： 方法里的Java代码，经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为“Code”的属性里面，属性表作为Class文件格式中最具扩展性的一种数据项目，见下一节。 与字段表集合相对应的，如果父类方法在子类中没有进行重写（Override），方法表集合中就不会出现来自弗雷德方法信息。但同样有可能出现由编译器自动添加的方法，最典型的便是类构造器方法和实例构造器方法。 Java语言中，要重载（Overload）一个方法，除了要与原方法具有相同的简单名称之外，还要求必须拥有一个与原方法不同的特征签名，特征签名就是一个方法中各个参数在常量池中的字段符号引用的集合，也就是因为返回值不会包含在特征签名中，因此Java语言无法仅仅依靠返回值的不同来对一个已有方法进行重载。 属性表集合在Class文件、字段表、方法表都可以携带自己的属性表集合，以用于描述某些场景专有的信息。 12u2 attributes_count; //此类的属性表中的属性数attribute_info attributes[attributes_count]; //属性表集合 属性表的限制相对其他的数据项目稍微宽松了一些，不再要求各个属性表具有严格的顺序，并且只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略它不认识的属性。 对于每个属性，它的名称需要从常量池中引用一个CONSTANT_Utf8_info类型的常量来标识，而属性值的结构则是完全自定义的，只需要通过一个u4的长度属性去说明属性值所占用的位数即可。 Code属性Java程序方法体中的代码经过Javac编译器处理后，最后变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合之中，但并非所有的方法表都必须存在这个属性，譬如接口或者抽象类中的方法就不存在Code属性。 attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引，常量值固定为“Code”，它代表该属性的属性名称。 attribute_length指示了属性值的长度，由于属性名称索引与属性长度一共为6字节，所以属性值的长度固定为整个属性表长度减去6个字节。 max_stack代表了操作栈数深度的最大值。 max_locals代表了局部变量表所需的存储空间，单位是Slot，Slot时虚拟机为局部变量分配内存所使用的最小单位。对于byte、char、float、int、short、boolean和returnAdress等长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这种64位的数据类型则需要两个Slot来存放。并不是在方法中用到了多少个局部变量，就把这些局部变量所占Slot之和作为max_locals的值，原因是局部变量表中的Slot可以重用，当代码执行超过一个局部变量的作用域时，这个局部变量所占的Slot可以被其他局部变量所使用，Javac编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_locals的大小。 code_length和code用来存储Java源程序编译后生成的字节码指令，code_length代表字节码长度，code是用于存储字节码指令的一系列字节流，每个指令长度为u1类型的单字节，虚拟机每次读入一个字节码指令。关于code_length，虽然他是一个u4类型的长度值，但虚拟机明确限制了一个方法不允许超过65535条字节码指令，即它实际只使用了u2的长度。 在实例方法的局部变量表中至少会存在一个指向当前对象实例的局部变量，局部变量表中也会预留出一个Slot位来存放对象实例的引用，方法参数值从1开始计算。 exception_table：异常表如下。如果当字节码在第start_pc行到第end_pc行之间（不含end_pc行）出现了类型为catch_type或者其子类的异常（catch_type为指向一个CONSTANT_Class_info型常量的引用），则转到第handler_pc行继续处理。当catch_type的值为0时，代表任意异常情况都需要转向到handler_pc行进行处理。 Exceptions属性Exceptions属性的作用是列举出方法中可能抛出的受查异常（Checked Exceptions），也就是方法描述时在throws关键字后面列举的异常。Exceptions属性中的number_of_exceptions项表示方法可能抛出number_of_exceptions种受查异常。每一种受查异常使用一个number_index_table项表示，exception_index_table是一个指向常量池中CONSTANT_Class_info型常量的索引，代表了该受查异常的类型。 LineNumberTable属性LineNumberTable属性用于描述Java源码行号与字节码（字节码的偏移量）之间的对应关系。line_number_table是一个数量为line_number_table_length、类型为line_number_info的集合，line_number_info表包括了start_pc和line_number两个u2类型的数据项，前者是字节码行号，后者是Java源码行号。 LocalVariableTable属性LocalVariableTable属性用于描述栈帧中局部变量表中与Java源码中定义的变量之间的关系。 start_pc和length属性分别代表了这个局部变量的生命周期开始地字节码偏移量及其作用范围覆盖的长度，两者结合起来就是这个局部变量在字节码之中的作用域范围。 name_index和descriptor_index都是指向常量池中CONSTANT_Utf8_info型常量的索引，分别代表了局部变量的名称以及这个局部变量的描述符。 index是这个局部变量在栈帧局部变量表中Slot的位置。当这个变量数据类型是64位类型时（double和long），他占用的Slot为index和index+1两个。 在JDK1.5引入泛型之后，LocalVariableTable属性增加了一个“姐妹属性”：LocalVariableTypeTable，这个新增的属性结构与LocalVariableTable非常相似，仅仅是吧记录的字段描述符的descriptor_index替换成了字段的特征签名（Signature），对于非泛型类型来说，描述符和特征签名能描述的信息是基本一致的，但是泛型引入后，由于描述符中反省的参数化类型被擦除掉，描述符就不能准确的描述泛型类型了，因此出现了LocalVariableTypeTable。 SourceFile属性SourceFile属性用于记录生成这个Class文件的源码文件名称。sourcefile_index数据项是指向常量池中CONSTANT_Utf8_info型常量的索引，常量值是源码文件的文件名。 ConstantValue属性ConstantValue属性的作用是通知虚拟机自动为静态变量赋值。只有被static关键字修饰的变量（类变量）才可以使用这项属性。对于非static类型的变量的赋值是在实力构造器方法中进行的；而对于类变量，则有两种方式可以选择：再类构造器方法中或者使用ConstantValue属性。 从数据结构中可以看出，ConstantValue属性是一个定长属性，他的attribute_length数据项值必须固定为2。constantvalue_index数据项代表了常量池中一个字面量常量的引用，根据字段类型的不同，字面量可以是CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_Integer_info、CONSTANT_String_info常量中的一种。 InnerClasses属性Inner属性用于记录内部类与宿主类之间的关联。如果一个类中定义了内部类，那编译器将会为它以及它所包含的内部类生成InnerClasses属性。 Deprecated及Synthetic属性Depreciated和Syntactic两个属性都属于标志类型的布尔属性，只存在有和没有的区别，没有属性值的概念。 Depreciated属性用于表示某个类、字段或者方法，已经被程序作者定为不再推荐使用，它可以通过在代码中使用@deprecated注解进行设置。 Syntactic属性代表此字段或者方法并不是由Java源码直接产生的，而是由编译器自行添加的。唯一例外的是实例构造器方法和类构造器方法。 StackMapTable属性StackMapTable属性在JDK1.6发布后增加到Class文件规范中，它是一个复杂的变长属性，位于Code属性的属性表中。 这个属性会在虚拟机类加载的字节码验证阶段被新类型检查验证器使用，目的在于代替以前比较消耗性能的基于数据流分析的类型推导验证器。 Signature属性Signature属性在KJDk1.5发布后增加到了Class文件规范中，他是一个可选的定长类属性，可以出现于类、字段表、和方法表结构的属性表中。 在JDK 1.5大幅增强了Java语言的语法，在此之后，任何类、接口、初始化方法或成员的泛型签名如果包含了类型变量（Type Variables）或参数化类型（Parameterized Types），则Signature属性会为它记录泛型签名信息。之所以要专门使用这样一个属性去记录泛型类型，是因为Java语言的泛型采用的是擦除法实现的伪泛型。 使用擦除法的好处是实现简单（主要修改Javac编译器，虚拟机内部只做了很少的改动）、非常容易实现Backport，运行期也能够节省一些类型所占的内存空间。但坏处是运行期就无法像C#等有真泛型支持的语言那样，将泛型类型与用户定义的普通类型同等对待，例如运行期做反射时无法获得到泛型信息。Signature属性就是为了弥补这个缺陷而增设的。 BootstrapMethods属性BootstrapMethods属性在JDK1.7发布后增加到了Class文件规范之中，它是一个复杂的变长属性，位于类文件的属性表中。这个属性用于保存invokeddynamic指令引用的引导方法限定符。目前的Javac暂时无法生成InvokeDynamic指令和BootstrapMethods属性，必须通过一些非常规的手段才能使用它们。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机性能监控与故障处理工具]]></title>
    <url>%2Fposts%2F61312%2F</url>
    <content type="text"><![CDATA[JDK的命令行工具JDK的bin目录中除了有我们所熟知的“java.exe”、“Javac.exe”这两个命令行工具，还有也许我们并不了解的其他命令行工具。这里我们主要介绍一些用于监视虚拟机和故障处理的工具，这些关工具都非常稳定而且功能强大，能在处理应用程序性能问题、定位故障时发挥很大的作用。 这些命令行工具大多数是jdk/lib/tool.jar类库的一层薄包装而已，它们主要的功能代码是在tools类库中实现的。JDK开发团队选择采用Java代码来实现这些监控工具是有特别用意的：当应用程序部署到生产环境后，无论是直接接触物理服务器还是远程Telnet到服务器上都可能会受到限制，借助tools.jar类库里面的接口，我们可以直接在应用程序中实现功能强大的监控分析功能。 Sun JDK 监控和故障处理工具： 名称 主要作用 jps JVM Process Status Tool ， 显示指定系统内所有的HotSpot虚拟机进程 jstat JVM Statistics Monitoring Tool ， 用于收集HotSpot虚拟机各方面的运行数据 jinfo Configuration In for Java ， 显示虚拟机配置信息 jmap Memory Map for Java ， 生成虚拟机的内存转储快照（heapdump文件） jhat JVM Heap Dump Browser ， 用于分析headgump文件，它会建立一个HTTP/HTML服务器，让用户可以在浏览器上查看分析结果 jstack Stack Trace for Java ， 显示虚拟机的线程快照 jps：虚拟机进程状况工具JDK的很多小工具的命名方式采用了UNIX命令的命名方式，jps就是其中的典型，它的作用就是类似于UNIX的ps命令： 可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main() 函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Mechain Identifier，LVMID）。对于本地虚拟机进程来说，LVMID与操作系统的进程ID是一致的。 jps命令格式： 1jps [options] [hostid] jps工具主要选项： 选项 作用 -q 只输出LVMID，省略主类的名称 -m 输出虚拟机进程启动时，传递给主类main()函数的参数 -l 输出主类全名，如果进程执行的是Jar包，输出Jar路径 -v 输出虚拟机启动时JVM参数 jstat：虚拟机统计信息监视工具jstat是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 jstat命令格式： 1jstat [option vmid/lvmid [interval[s|ms] [count]] ] vmid/lvmid分别是远程虚拟机进程与本地虚拟机进程。参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。 option主要分为三类：类装载、垃圾收集、运行期编译。jstat工具主要选项： 选项 作用 -class 监视类装载、卸载数量、总空间以及类装载所耗费的时间 -gc 监视Java堆状况，包括Eden区、两个Survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息 -gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因 -gcnew 监视新生代GC状况 -gcnewcapacity 监视内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间 -gcold 监视老年代GC状况 -gcoldcapacity 监视内容与-gcold基本相同，输出主要关注使用到的最大、最小空间 -gcpermcapacity 输出永久代使用到的最大、最小空间 -compiler 输出JIT编译器编译过的方法、耗时等信息 -printcompilation 输出已经被JIT编译过的方法 jinfo：Java配置信息工具jinfo的作用是实时地查看和调整虚拟机各项参数。 jinfo的-flag选项可以查询未被显式指定的参数的系统默认值，可以使用-flag [+|-]或者-flag name=value修改一部分运行期可写的虚拟机参数值 。jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties()的内容打印出来。 jamp：Java内存映像工具jmap命令用于生成堆转储快照（一般为heapdump或者dump文件），如果不使用 jmap 命令，要想获取 Java 堆转储，可以使用 “-XX:+HeapDumpOnOutOfMemoryError” 参数，可以让虚拟机在 OOM 异常出现之后自动生成 dump 文件，Linux 命令下可以通过 kill -3 发送进程退出信号也能拿到 dump 文件。它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前使用的是哪种收集器等。和jinfo一样，jmap有不少功能在 Windows 平台下也是受限制的。 jamp命令格式： 1jmap [option] vmid jmap工具主要选项： 选项 作用 -dump 生成Java堆转出快照。格式为：-dump[live,]format=b,file=,其中live子参数说明是否只dump出存活对象 -finalizerinfo 显示在F-Queue中等待Finalizer线程等待执行finalize方法的对象。只在Linux/Solaris平台下有效 -heap 显示Java堆详细信息，如使用哪种回收器、参数配置、分代状况等。 -histo 显示堆中对象统计信息，包括类、实例数量、合计容量 -permstat 已ClassLoader为统计口径，显示永久代内存状况。只在Linux/Solaris平台下有效 -F 当虚拟机进程堆-dump选项没有响应时，可使用这个选项强制生成dump快照。只在Linux/Solaris平台下有效 jhat：虚拟机堆转储快照分析工具jhat与jmap搭配使用，来分析jmap生成的堆转储快照，可以在浏览器中查看。 但是一般不会直接使用jhat命令来分析dump文件，主要原因有二： 一般不会在部署应用程序的服务器上直接分析dump文件，即使可以这样做，也会尽量将dump文件复制到其他机器上分析，因为分析是一个耗时而且消耗硬件资源的过程，尽然都要在其他机器上进行，就没有必要受到命令行工具的限制了。 jhat的分析功能相对来说比较简陋，有更强的工具可以代替它。 jamp命令格式： 1jhat filename jstack：Java堆栈跟踪工具jstack命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么，或者等待什么资源。 线程快照就是当前虚拟机每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。 jstack命令格式： 1jstack [option] vmid jmap工具主要选项： 选项 作用 -F 当正常输出的请求不被响应时，强制输出线程堆栈 -l 除堆栈外，显示关于锁的附加信息 -m 如果调用到本地方法的话，可以显示C/C++的堆栈 JDK的可视化工具JDK中除了提供大量的命令行工具外，还有两个功能强大的可视化工具：JConsole和VisualVM。 JConsole：Java监视与管理控制台JConsole是一种基于JMX的可视化监视、管理工具。它管理部分的功能是针对JMX MBean进行管理。 启动JConsole提供JDK/bin目录下的“jconsole.exe”启动JConsole后，将自动搜索出本机运行的所有虚拟机进程，双击选择其中一个进程即可开始监控，也可以使用下面的“远程进程”功能来连接远程服务器，对远程虚拟机进行监控。“概述”页签显示的是整个虚拟机主要运行数据的概览，其中包括“堆内存使用情况”、“线程”、“类”、“CPU使用情况”4种信息的曲线图。 内存监控JConsole可以显示当前内存的详细信息，不仅包括堆内存/非堆内存的整体信息，还可以细化到Eden区、Survivor区等的使用情况。点击右边的“执行 GC(G)”按钮可以强制应用程序执行一个Full GC。 线程监控类似于jstack命令，遇到线程停顿时可以使用这个页签进行监控分析。最下面有一个”检测死锁 (D)”按钮，点击这个按钮可以自动为你找到发生死锁的线程以及它们的详细信息 。 VisualVM：多合一故障处理工具VisualVM是到目前为止随JDK发布的功能最强大的运行监视和故障处理程序。它除了运行监视、故障处理外，还提供了很多其他方面的功能，如性能分析。 VisualVM还有一个很大的优点：不需要被监视的程序基于特殊Agent运行，因此它对应用程序的实际性能的影响很小，使得它可以直接应用在生产环境中。 VisualVM 基于 NetBeans 平台开发，因此他一开始就具备了插件扩展功能的特性，通过插件扩展支持，VisualVM 可以做到： 显示虚拟机进程以及进程的配置、环境信息（jps、jinfo）。 监视应用程序的CPU、GC、堆、方法区以及线程的信息（jstat、jstack）。 dump以及分析堆转储快照（jmap、jhat）。 方法级的程序运行性能分析，找出被顶用最多、运行时间最长的方法。 离线程序快照：收集程序的运行时配置、线程dump、内存dump等信息建立一个快照，可以将快照发送开发者除进行Bug反馈。 其他plugins的无限的可能性……]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存分配与回收策略]]></title>
    <url>%2Fposts%2F44680%2F</url>
    <content type="text"><![CDATA[Java技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。 对象的内存分配，往大方向讲，就是在堆上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲（TLAB），将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配堆规则并不是百分之百固定的。 新生代GC和老年代GC在了解分配策略之前，先了解一下新生代（Minor）GC和老年代（Full/Major）GC有什么不同。 新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。 老年代GC（Major/Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但并非绝对，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。 对象优先在Eden分配大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。 当给一个对象分配内存的的时候，发现Eden已经被占用的了一部分,剩余的空间已不足以分配当前对象所需的内存，因此发生Minor GC。GC期间虚拟机首先尝试把Eden中的对象放入Survivor空间中，如果Survivor中的空间大小不足的话，就会通过分配担保机制提前转移到老年代去。 大对象直接进入老年代所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组。 虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配，这样做的目的是避免Eden区及两个Survivor区之间发生大量的内存复制（新生代采用复制算法收集内存）。 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在Eden出生经过一次Minor GC后仍然存活，并且能够被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。 对象在Survivor区中每熬过一次Minor GC，年龄就增加1岁，当他的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代中的阈值，可以通过参数-XX:MaxTenuringThreshold设置。 动态对象年龄判定为了更好的适应不同程序的内存状况，虚拟机并不是永远的要求对象的年龄达到了阈值才能晋升到老年代中，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 空间分配担保在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。 取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。 虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解GC日志]]></title>
    <url>%2Fposts%2F41052%2F</url>
    <content type="text"><![CDATA[每一种收集器的日志形式都是由它们自身的实现所决定的,换而言之,每个收集器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读,将各个收集器的日志都维持一定的共性,例如以下两段典型的GC日志: 12333.125: [GC [DefNew: 3324K-&gt;152K(3712K), 0.0025925 secs] 3324K-&gt;152K(11904K), 0.0031680secs]100.667: [Full GC [Tenured: 0K-&gt;210K(10240K), 0.0149142 secs] 4603K-&gt;210K(19456K), [Perm : 2999K-&gt;2999K(21248K)], 0.0150007 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] 最前面的数字“33.125”和“100.667”：代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数。 GC日志开头的“[GC”和“[Full GC”说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC的。如果有“Full”，说明这次GC是发生了Stop-The-World的。 接下来的“[DefNew”、“[Tenured”、“[Perm”表示GC发生的区域，这里显示的区域名称与使用的GC收集器是密切相关的。例如上面Serial收集器中的新生代名为“Default NewGeneration”，所以显示的收集“[DefNew”。如果是ParNew收集器，新生代名称就会变为“[ParNew”，意为“Parallel New Generation”。如果采用Parallel Scavenge收集器，那它配套的新生代为“PSYoungGen”，老年代和永久代同理,名称也是由收集器决定的。 后面方括号内部的“3324K-&gt;152K(3712K)” 含义是 “GC前该区域已使用容量 -&gt; GC后该区域已使用容量（该内存区域总容量）”。 而在方括号之外的“3324K-&gt;152K(11904K)” 表示 “GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量（Java堆总容量）”。 再往后，“0.0031680secs”表示该内存区域GC所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如“[Times: user=0.01 sys=0.00, real=0.02 secs]”，这里面的user、sys和real与Linux的time命令所输出的含义一致，分别代表用户态消耗的CPU时间、内核态消耗的CPU时间和操作从开始到结束所经过的墙钟时间。 CPU时间与墙钟时间的区别是,墙钟时间包括各种非运算的等待耗时,例如等待磁盘I/O、等待线程阻塞,而CPU时间不包括这些耗时,但当系统有多CPU或者多核的话,多线程操作会叠加这些CPU时间,所以读者看到user或sys时间超过real时间是完全正常的。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集器]]></title>
    <url>%2Fposts%2F51819%2F</url>
    <content type="text"><![CDATA[本文索引关于内存分配和回收策略会在下一篇博文中讲解，本文就主要讲解后面三个关于GC的问题。 对象已经死亡吗？在里面存放着Java世界中几乎所有的对象实例，垃圾收集器在对堆进行回收之前，第一件事情就是要确定这些对象之中那些还“存活”着，哪些已经“死去”（即不可能再被任何途径使用的对象）。 引用计数算法引用计数法的算法是这样的：给对象添加一个引用计数器，每当有一个地方引用它时，计数器的值就加一；当引用失效时，计数器的值就减一；任何时刻计数器为零的对象就是不可能再被使用的。 虽然客观的说，引用计数算法的实现很简单，判定效率也很高，在大部分情况下它都是一个不错的算法。但是，至少主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因就是它很难解决对象之间相互循环引用的问题。 具体的例子如下： 1234567891011public class ReferenceCountingGc &#123; Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; &#125;&#125; 对象objA和objB都有字段instance，赋值令 objA.instance = objB及objB.instance = objA，除此之外，这两个对象再无任何引用，实际上这两个对象不可能再被访问，但是他们因为互相引用着对方，导致它们的引用计数都不为零，于是引用计数算法无法通知GC回收它们。 可达性分析算法这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。 在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法中JNI（即一般说的Native方法）引用的对象 再谈引用在JDK1.2之前，Java中引用的定义很传统：如果reference类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用在JDK1.2之后，Java对引用的概念进行了扩充，将引用分为 强引用、软引用、弱引用、虚引用 四种，这四种引用强度依次逐渐减弱。 强引用强引用（Strong Reference）就是指在程序代码中普遍存在的，类似Object obj = new Object()这类的引用，我们使用的大部分引用实际上都是强引用。 只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。当内存空间不足，Java虚拟机宁愿抛出 OutOfMemoryError错误，使程序异常终止，也不会随意回收具有强引用的对象来解决内存不足的问题。 软引用软引用（Soft Reference）是用来描述一些还有用，但是并非必需的对象。 如果内存空间足够，垃圾收集器就不会回收它；如果内存空间不足，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够内存的话，才会抛出内存溢出异常。 弱引用弱引用（Weak Reference）也是用来描述非必需的对象，但是它的强度更弱，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。 当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。不过由于垃圾收集器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 虚引用虚引用（Phantom Reference）顾名思义，就是形同虚设，它是最弱的一种引用关系。 一个对象是否具有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象的实例。 为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 在程序中一般很少使用弱引用和虚引用，使用软引用的情况比较多，因为软引用可以加速Java虚拟机堆垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemoryError）等问题发生。 生存还是死亡即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，要真正宣告一个对象死亡，至少要经历两次标记过程： 如果对象在可达性分析后发现没有与GC Roots相连接的引用链，那它将会被标记并且进行第一次筛选，筛选的条件是此对象是否有必要执行finalize（）方法。当对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。 如果这个对象被判定有必要执行finalize（）方法，那么这个对象将会被放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。 被判定为需要执行的对象，将会被放在F-Queue队列中进行二次标记。如果对象在finalize（）中成功拯救了自己————只要重新与引用链上的任何一个对象建立关联即可，譬如把自己赋值给某个类变量或者对象的成员变量，那在第二次标记的时候它将被移除出“即将回收”的集合；如果这个对象这时候还没有逃脱，那他基本上就真的被回收了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* * 此代码演示了两点： * 1.对象可以再被GC时自我拯救 * 2.这种自救的机会只有一次，因为一个对象的finalize()方法最多只会被系统自动调用一次 * */public class FinalizeEscapeGC &#123; public String name; public static FinalizeEscapeGC SAVE_HOOK = null; public FinalizeEscapeGC(String name) &#123; this.name = name; &#125; public void isAlive() &#123; System.out.println("yes, i am still alive :)"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println("finalize method executed!"); System.out.println(this); FinalizeEscapeGC.SAVE_HOOK = this; &#125; @Override public String toString() &#123; return name; &#125; public static void main(String[] args) throws InterruptedException &#123; SAVE_HOOK = new FinalizeEscapeGC("leesf"); System.out.println(SAVE_HOOK); // 对象第一次拯救自己 SAVE_HOOK = null; System.out.println(SAVE_HOOK); System.gc(); // 因为finalize方法优先级很低，所以暂停0.5秒以等待它 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println("no, i am dead : ("); &#125; // 下面这段代码与上面的完全相同,但是这一次自救却失败了 // 一个对象的finalize方法只会被调用一次 SAVE_HOOK = null; System.gc(); // 因为finalize方法优先级很低，所以暂停0.5秒以等待它 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println("no, i am dead : ("); &#125; &#125;&#125; 运行结果： 123456leesfnullfinalize method executed!leesfyes, i am still alive :)no, i am dead : ( 从上面的运行结果可以看出，SAVE_HOOK对象的finalize（）方法确实被GC收集器触发过，并且在被收集前成功逃脱了。但是在第二次执行相同代码的时候，却逃脱失败，这是因为任何一个对象的finalize（）方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize（）方法不会被再次执行，因此第二段代码的自救行动失败。 回收方法区很多人认为方法区是没有垃圾收集器的，虽然在方法区进行垃圾收集的性价比比较低，但是也并不代表在方法区去就一定没有垃圾收集的工作。 永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。 回收废弃常量与回收Java堆中的对象非常相似，以字符串为例，如果当前没有任何String对象引用常量池中的该字符串常量，也没有其他地方引用了这个字面量，就说明这个字符串常量为废弃常量。如果这是发生内存回收，而且有必要的话，这个常量就会被系统清理出常量池。 而判定一个类是否为“无用的类”的条件则苛刻的多，类需要同时满足下面三个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类。 虚拟机可以对满足上述三个条件的无用类进行回收，这里说的仅仅是“可以”，并不是必然被回收。 垃圾收集算法由于垃圾收集算法的实现涉及大量的程序细节，且各个平台的虚拟机操作内存的方法又各不相同，因此这里不过多的讨论实现的细节，仅介绍几种算法的思想。 标记-清除算法最基础的算法就是“标记-清除（Mark-Sweep）”算法，顾名思义，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 它的标记过程在前一节已经介绍过了，而且之所以说它是最基础的算法，因为后续的收集算法都是基于这种思路，并对其不足进行改进而得到的。 它的不足有两个： 效率问题：标记和清除两个过程的效率都不高。 空间问题：标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后再程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法复制算法是为了解决标记-清除算法的效率问题，它将内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免有点太高。 有统计表示，新生代中的对象98%是“朝生息死”的，所以并不需要按照1：1的比例来划分内存空间。 而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当Eden满了时，触发一次Minor GC，然后将Eden和Survivor中还存活着的对象一次性的复制到另一块Survivor空间上（这个过程非常重要，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生），最后清理掉Eden和刚刚使用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8：1。 如此循环往复，如果对象的复制次数达到了16次，该对象就会被送到老年代中。 其次当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。大对象（就是需要大量连续内存空间的对象）直接进入老年代，因为这样做为了避免大对象分配内存时由于分配担保机制带来的复制而降低效率。 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。 标记-整理算法因为复制算法的缺点，根据老年代的特点，有人提出另一种“标记-整理”算法。 标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”算法。这种算法把“复制算法”和“标记-整理”结合起来，根据对象存活周期的不同将内存划分为几块，把Java堆划分为新生代和老年代，根据各个年代的特点选择合适的垃圾收集算法。 新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或者“标记-整理”算法来进行回收。 垃圾收集器如果说收集算法时内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。 Serial收集器Serial收集器是最基本、发展历史最悠久的收集器。这个收集器是一个单线程的收集器，但它的“单线程”意义并不仅仅说明它只会使用一个CPU或者一条收集线程去完成垃圾收集工作，更重要的是他在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集完成。新生代采用复制算法，老年代采用标记-整理算法。 虽然现在一个个越来越优秀的收集器出现，用户线程的停顿时间在不断缩短，但是仍然没有办法完全消除。 但实际上到现在为止，它依然是虚拟机运行在Client模式下的默认新生代收集器。它的优点如下：简单而高效，对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集之外，其余行为（控制参数、收集算法、回收策略等等）都与Serial收集器完全一样。新生代采用复制算法，老年代采用标记-整理算法。 它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果。 并发和并行概念的补充 并行：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续执行，而垃圾收集程序运行在另一个CPU上。 Parallel Scavenge收集器Parallel Scavenge收集器收集算法和线程方面与ParNew收集器一样，但Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量，因此该收集器也被称为“吞吐量优先”收集器。 该收集器提供了两个参数用于精确控制吞吐量，分别控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。 该收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注，这是一个开关参数。当这个参数打开之后，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略。这也是该收集器与ParNew收集器的一个重要区别。 Serial Old收集器该收集器是Serial收集器的老年代版本。它主要的两大用途： 在JDK1.5以及之前的版本中与Parallel Scavenge收集器搭配使用。 作为CMS收集器的后备预案。 Parallel Old收集器Parallel Old收集器是Parallel Scavenge收集器的老年代版本。在注重吞吐量以及CPU资源的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。工作过程如图所示。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它是HotSpot虚拟机第一款真正意义上的并发收集器，他第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 CMS收集器是基于“标记-清除”算法实现的，整个过程分为4个步骤： 初始标记：暂停所有的其他线程，并记录下直接与GC Roots能直接关联的对象，速度很快。 并发标记：同时开启GC和用户线程,从GC Roots开始对堆中对象进行可达性分析,找出存活的对象，这阶段耗时较长。 重新标记：暂停所有的其他线程，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 并发清除：开启所有线程，同时GC线程对为标记的区域做清扫。 因为它的性能优点，也称它为并发低停顿收集器。但是它有以下三个明显的缺点： CMS收集器对CPU资源非常敏感。在并发阶段虽然不会导致用户线程停顿，但是会因为占用一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量降低。 CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于用户程序在运行，那么自然就会有新的垃圾产生，这部分垃圾被标记过后，CMS无法在当次集中处理它们（为什么？原因在于CMS是以获取最短停顿时间为目标的，自然不可能在一次垃圾处理过程中花费太多时间），只好在下一次GC的时候处理。这部分未处理的垃圾就称为“浮动垃圾”。 这使得并发清除时需要预留一定的内存空间，不能像其他收集器在老年代几乎填满再进行收集。在JDK1.6中，CMS收集器启动阈值已经提升至92%。要是CMS运行期间的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机启用后备预案：临时启用Serail Old收集器，而导致另一次Full GC的产生。 收集结束时会有大量空间碎片产生。因为它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。，所以为了解决这个问题，CMS收集器提供了一个开关参数-XX:+UseCMSCompactAtFullCollection（默认开启），用于在CMS收集器顶不住要进行Full GC时开启内存碎片的合并整理过程，但是会导致停顿时间变长。 G1收集器G1收集器是当今收集器技术发展的最前沿成果之一，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。它具备以下特点： 并行与并发：G1能充分利用多CPu、多核环境下的硬件优势，使用多个CPU（或者CPU核心）来缩短Stop-The-Word停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续运行。 分代收集：同其他收集器一样保留了分代的概念，但是它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。 空间整合：不同于CMS的“标记-清除”算法，G1从整体看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法是实现的，但无论如何，这两种算法都意味着G1运行期间不会产生内存空间碎片。 可预测的停顿：这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M浩渺的时间片段内。 G1收集器中Java堆的内存布局与其他收集器有很大区别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留新生代和老生代的概念，但新生代和老生代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间吨经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也是Garbage-First名称的由来）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用Remembered Set 来避免全堆扫描的。G1中每个Region都有一个与之对应的Remembered Set，如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤： 初始标记：仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top At Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象。这阶段需要停顿线程，但耗时很短。 并发标记：这阶段是从GC Roots开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记：这阶段则是为了修正在并发标记阶段期间因用户程序继续运行而导致标记产生变化的那一部分标记记录，虚拟机将这段时间变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但可并行执行。 筛选回收：最后首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行。 垃圾收集器参数总结]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HotSpot 虚拟机对象探秘]]></title>
    <url>%2Fposts%2F58276%2F</url>
    <content type="text"><![CDATA[对象的创建下图便是一个Java对象创建的过程 类加载检查在Java程序运行期间无时无刻都有对象被创建出来，在语言层面来说，创建对象通常仅仅是一个new关键字而已，而在虚拟机中，遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存在类加载检查通过之后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可完全确定（具体将在下一节介绍）。 为对象分配内存空间的任务等于把一块确定大小的内存从Java堆中划分出来。分配方式有两种：“内存碰撞”和“空闲列表”，选择哪种方式由Java堆是否规整决定，而Java堆是否规整取决于虚拟机所采用的垃圾收集器是否带有压缩整理功能。 指针碰撞：Java堆中内存是绝对规整的，所有用过的内存放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那么分配内存就是把指针向空闲空间那边挪动对象大小的距离即可。 空闲列表：如果Java堆中内存并不是规整的，已使用的内存与空闲的内存相互交错，那么虚拟机就必须维护一个列表，记录那些内存是可用的，在分配的时候从列表中找到一块足够大的内存空间划分给对象实例，并更新列表上的记录。 因为在虚拟机中对象创建是一个非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发的情况下也并不是线程安全的。可能出现正在给A对象分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。所以对于内存分配引发的并发问题有两种解决方案：CAS+失败重试和本地线程分配缓冲（TLAB） CAS+失败重试：以这种方式保证更新操作的原子性。 本地线程分配缓冲（TLAB）：把内存分配堆动作按线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，每个线程在自己的TLAB上分配内存，只有当对象大于TLAB中的剩余内存或者TLAB用完时，采用同步锁定（synchronized）的方式分配新的TLAB。 初始化零值内存分配完成后，虚拟机将对分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一步可以提前至TLAB分配时进行。 这一步的操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象头初始化零值之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息都存放在对象头中。 根据虚拟机当前的运行状态不同，如是否启用偏向锁等，对象头会有相应的不同的设置方式，具体会在下一节做详细介绍。 执行init方法在上面四个步骤完成之后，在Java虚拟机的角度，一个新的对象已经产生了；但是在Java程序的角度来看，对象的创建才刚开始，&lt;init&gt;方法还没有执行，所有的字段都是零。 所以一般来说，执行new指令之后会接着执行&lt;init&gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象的内存布局在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头HotSpot虚拟机的对象头包括两部分信息:Mark Word 和 类型指针（Class Pointer）。 Java虚拟机中对象头的方式有以下俩种（以32位Java虚拟机为例）：普通对象：数组对象： Mark Word第一部分用于存储对象自身的运行时数据（mark Word），如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，也就是一个Word的大小，官方称它为“Mark Word”。 对象需要存储的运行时数据很多时，如果超出了32位或64位Bitmap结构所能记录的限度。考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多信息，它会根据对象的状态复用自己的存储空间。 大部分情况下，Mark Word的32bit空间中的25bit用于存储对象哈希码，4bit用于存储对象分代年龄，2bit用于存储锁状态标志位，1bit用于标记对象是否启用偏向锁 不同锁状态标志位标记位表示的整个Mark Word含义不同，具体如下： 其中各部分的含义如下： lock : 2位的锁状态标记位，该标记的值不同，整个Mark Word表示的含义不同。 存储内容 biased_lock lock（标记位） 状态 对象的哈希码、分代年龄 0 01 无锁 偏向线程ID、偏向时间戳、对象分代年龄 1 01 偏向锁 指向锁记录的指针 0 00 轻量级锁 指向重量级锁的指针 0 10 重量级锁 空，不需要记录信息 0 11 GC标记 biased_lock : 只占1位，用于标记对象是否启用偏向锁。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。 age ： 4位的Java对象分代年龄。由于只有4位，所以最大值为15。 identity_hashcode ： 25位的对象标识哈希码，采用延迟加载技术。调用System.identityHashCode()计算，并会将结果写到该对象头中。当对象被锁定时，该值会移动到管程Monitor中。 thread ： 占23位，表示持有偏向锁的线程ID。 epoch ： 占2位，表示偏向时间戳。 ptr_to_lock_record ： 占30位，指向栈中锁记录的指针。 ptr_to_heavyweight_monitor ： 占30位，指向管程Monitor的指针。 类型指针对象头的另一部分就是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 该指针的位长度为JVM的一个字大小，即32位的JVM为32位，64位的JVM为64位。如果应用的对象过多，使用64位的指针将浪费大量内存，统计而言，64位的JVM将会比32位的JVM多耗费50%的内存。为了节约内存可以开启压缩指针（+UseCompressedOops），，其中，OOPS（ordinary object pointers），即普通对象指针。开启该选项后，下列指针将压缩至32位： 每个Class的属性指针（即静态变量） 每个对象的属性指针（即对象变量） 普通对象数组的每个元素指针 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，这部分数据的长度也随着JVM架构的不同而不同：32位的JVM上，长度为32位；64位JVM则为64位。 实例数据实例数据部分是对象真正存储的有效信息，也就是在程序代码中所定义的各种类型的字段。 这部分的存储顺序会受到虚拟机分配策略和字段在Java源码中定义的顺序的影响，HotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、OOPS（ordinary object pointers），从这个分配策略可以看出，子类中较窄的变量也可能会插入到父类变量的空隙之中。 对齐填充第三部分对齐填充并不是必然存在的，也没有特别的含义，仅仅起着占位符的作用，因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 关于对象头的具体实现处，可以参考ArrayList的数组默认最大长度（Integer.MAX_VALUE - 8）。 对象的访问定位建立对象就是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象。 而由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，没有定义这个引用该通过何种方式去定位、访问堆中的对象的具体位置。所以目前主流的访问方式有两种：句柄和直接指针。 句柄如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中储存的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。如图所示： 直接指针如果使用直接指针，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference在储存的直接就是对象的地址。如图所示： 句柄和直接指针对比这两种方式各有优势。 句柄方式的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（GC回收时移动对象是非常普遍的行为）时只会改变句柄中的示例数据指针，而reference本身不需要改变。 直接指针方式的最大好处就是速度更快，它节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存区域]]></title>
    <url>%2Fposts%2F35314%2F</url>
    <content type="text"><![CDATA[运行时数据区域Java虚拟机（JVM）在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。而在JDK1.8前后数据区域的划分略有不同，下面会介绍到。JDK1.8之前：JDK1.8： 因此根据上面的运行时数据区划分图可以看出： 线程私有的： 程序计数器 虚拟机栈 本地方法栈 线程共享的： 堆 方法区 直接内存（非运行时数据区的一部分） 下面就按照上面的顺序逐个进行了解。 程序计数器程序计数器是一块较小的内存空间。在虚拟机的概念模型里面，字节码解释器工作时需要知道该执行哪一条字节码指令，而程序计数器的作用就是，通过改变程序计数器的值，来让字节码解释器知道，下一条需要执行的指令是什么。 其次，Java虚拟机的多线程执行，是通过线程之间轮流执行，而对于一个处理器（如果是多核处理器，那么就是一个内核），在任意一个确定的时刻，只会执行一条线程中的指令。因此，为了避免一个线程过长时间（可能因为计算时间过长或者陷入死循环等原因）占用处理器，导致系统崩溃，所以处理器会给每个线程分配执行的时间，如果当分配的时间结束时，该线程的任务还没有执行完，处理器会被剥夺并分配给另一个线程，直到到达下一次该线程的时间片，处理器才会切换回来，继续执行该线程。因此，为了线程切换后能恢复到正确的执行位置，所以每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 从上面的介绍中我们知道程序计数器主要有两个作用： 字节码解释器通过改变程序计数器，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理等。 在多线程情况下，程序计数器用于记录当前线程执行的位置，从而当线程切换回来的时候，能够知道该线程上次执行到哪里，接下来该执行什么指令。 注意： 如果线程正在执行的是一个Java方法，那么这个程序计数器是正在执行的方法的虚拟机字节码指令的地址。 如果线程正在执行的是一个Native方法，那么这个程序计数器则为空（Undefined）。因此程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 Java虚拟机栈Java虚拟机栈描述的是Java方法的内存模型，每次方法调用的数据都是通过栈传递的。而栈中储存的是一个个的栈帧，栈帧就是每个方法在执行的时候都会创建一个栈帧（Stack Frame），栈帧用于储存局部变量表、操作数栈、动态链接、方法出口等信息。因为线程每调用一个方法从开始到结束，都意味着一个栈帧在虚拟机栈中从入栈到出栈的过程。 Java内存可以粗糙的分为堆内存（Heap）和栈内存（Stack），其中的栈就是Java虚拟机栈，或者说是Java虚拟机栈中的局部变量表部分。 局部变量表存放了编译器可知的各种（八种）基本数据类型（boolean、byte、char、short、int、float、double、long）、对象引用（不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAdress类型（指向一条字节码指令地址）。其中64位的长度的double和long类型的数据都会占用两个局部变量空间，其余数据只会占用一个局部变量空间。局部变量表所需内存空间在编译期间完成分配，因此当进入一个方法时，这个局部变量表的大小就已经完全确定了，运行期间不会改变其大小。 Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError StackOverFlowError:若Java虚拟机栈的内存大小不允许动态扩展，那么如果线程请求的栈深度大于虚拟机所允许的最大深度，那么就会抛出StackOverFlowError异常。 OutOfMemoryError：若Java虚拟机栈的内存大小允许动态扩展，那么如果线程在扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 Java方法的返回方式有两种：return语句和抛出异常，不管哪种方法，都会导致栈帧出栈。 本地方法栈本地方法栈的作用与Java虚拟机栈的结构和作用几乎完全一样，可以认为二者唯一的区别就是：Java虚拟机栈为虚拟机执行Java方法（也就是字节码）服务；而本地方法栈为虚拟机执行Native方法服务。甚至在HotSpot虚拟机栈中将两者合二为一。 总结得到一点：程序计数器、Java虚拟机栈和本地方法栈都是线程所私有的，故而他们的生命周期和线程相同，它们的生命周期随着线程的创建而创建，随着线程的结束而死亡。 Java堆Java堆（Heap）是Java虚拟机所管理的内存中最大的一块。Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存的唯一目的就是：存放对象实例，几乎所有的对象实例都在这里分配，在Java虚拟机规范中的描述是：所有对象的实例以及数组都要在堆上分配。，但是随着JIT编译器的发展，这种情况也不是那么绝对的了。 java堆也是垃圾收集器管理的主要区域，因此也被称为 GC堆 ，从垃圾回收的角度看，Java堆中还可细分为：新生代和老生代；再度细分可分：Eden 空间、From Survivor、To Survivor 空间等为；大部分情况下，对象都会首先在Eden区域分配，再一次新生代垃圾回收后，如果对象还存活，则会进入s0或是s1在，并且对象年龄还加一，当他的年龄增加到一定程度（默认为15岁）时，就会被划分到老年代中。 不论如何划分，都与存放的内容无关；不论哪个区域，存储的都是对象的实例。进一步划分的目的是为了更好的回收内存，更快的分配内存。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。 Java堆的内存大小可以是固定大小的，也可以是可扩展的（大部分都是）。如果在堆中没有内存来完成实例的分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区方法区同样是各个线程共享的内存区域，它用于储存已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区有一个别名叫“非堆（Non-Heap）”，目的就是为了将其与Java堆区分开来。 仅在HotSpot虚拟机中，方法区也被称为“永久代”，仅仅是因为在HotSpot虚拟机中把GC分代收集扩展至方法区，这样可以省去专门为方法区编写内存管理代码的工作。但是问题也因此而来，因为永久代有大小上限，所以当触碰到内存大小的上限时，会抛出OutOfMemoryError异常。 所以在JDK1.8之后，永久代被彻底删除了，取而代之的是元空间（MetaSpace），与永久代有JVM本身内存大小上限的限制不同的是，元空间使用的是直接内存，受到的是本机可用内存的上限限制，只有当触碰到本地内存的极限时，才会抛出OutofMemoryError异常（概率极小）。 与java堆一样，方法区同样不需要连续的内存和可以选择固定大小或可扩展外，还可以选择不实现垃圾收集。相对而言垃圾收集行为在该区域比较少见，因为该区域内存回收目标主要是针对常量池的回收和对类型的卸载。 运行时常量池JDK1.7之前，运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息，用于存放编译期生成的各种字面量和符号引用。运行时常量池相对于Class文件常量池还有一个重要特征是具备动态性，将运行期间可能得到的新的常量放入池中。因此既然运行时常量池是方法区的一部分，所以当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 但是在JDK1.7及其之后版本的JVM中，将运行时常量池从方法区中移了出来，在Java堆中开辟了一块内存存放运行时常量池，这样也更加方便于垃圾回收的工作。 直接内存直接内存既不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这一部分内存被频繁的使用，而且也可能导致OutofMemoryError异常。 在JDK1.4中新加入了NIO类，引入了一种基于通道（Channel）于缓存区（Buffer）的I/O方式，它使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在Java堆和Native堆之间来回复制数据。 虽然本机直接内存并不会收到Java堆的内存大小限制，但是显然会受到本地总内存的大小限制，因此也可能会在动态扩展时抛出OutOfMemoryError异常。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码阅读]]></title>
    <url>%2Fposts%2F33665%2F</url>
    <content type="text"><![CDATA[ArrayList的数据结构ArrayList往往被人用来与LinkedList对比，它们俩最重要的差异之一就是：ArrayList的底层是由数组组成的，而LinkedList的底层则是由链表组成，对于LinkedList不再多赘述，具体可以看一下LinkedList的文章。回到ArrayList中来，其实现的数据结构是一个名为elementData的Object数组，可以存放所有Object对象，因此我们对ArrayList类的实例的所有的操作底层都是基于这个数组的。 顶部注释 List接口的可调整大小的数组实现。 实现所有可选列表操作，并允许所有元素，包括null 。 除了实现List接口之外，该类还提供了一些方法来处理内部用于存储列表的数组的大小。 （这个类大致相当于Vector ，除了它是不同步的。）该size ， isEmpty ， get ， set ， iterator ，并listIterator操作在固定时间内运行。 add操作以摊销的常数运行 ，即添加n个元素需要O（n）个时间。 所有其他操作都以线性时间运行（粗略地说）。 与LinkedList实现相比，常数因子较低。 每个ArrayList实例都有一个容量 。 容量是用于存储列表中的元素的数组的大小。 它总是至少与列表大小一样大。 当元素添加到ArrayList时，其容量会自动增长。 没有规定增长政策的细节，除了添加元素具有不变的摊销时间成本。 在使用ensureCapacity操作添加大量元素之前，应用程序可以增加ArrayList实例的容量。 这可能会减少增量重新分配的数量。 请注意，此实现不同步。 如果多个线程同时访问ArrayList实例，并且至少有一个线程在结构上修改列表，则必须在外部进行同步。 （结构修改是添加或删除一个或多个元素的任何操作，或明确调整后台数组的大小;仅设置元素的值不是结构修改。）这通常是通过在一些自然地封装了名单。 如果没有这样的对象存在，列表应该使用Collections.synchronizedList方法“包装”。 这最好在创建时完成，以防止意外的不同步访问列表： List list = Collections.synchronizedList(new ArrayList(…)); 由这个类的iterator和listIterator方法返回的迭代器是故障快速的 ：如果列表在迭代器创建之后的任何时间被结构地修改，除了通过迭代器自己的remove或add方法之外，迭代器将抛出一个ConcurrentModificationException 。 因此，面对并发修改，迭代器将快速而干净地失败，而不是在未来未确定的时间冒着任意的非确定性行为。 请注意，迭代器的故障快速行为无法保证，因为一般来说，在不同步并发修改的情况下，无法做出任何硬性保证。 失败快速的迭代器ConcurrentModificationException扔出ConcurrentModificationException 。 因此，编写依赖于此异常的程序的正确性将是错误的： 迭代器的故障快速行为应仅用于检测错误。 这个类是Java Collections Framework的成员。 总结上面的顶部注释可以得到以下几点： 底部实现：可调整大小的数组实现的。 是否允许null值：允许所有元素，包括null。 是否是线程安全的：不是线程安全的。 迭代器： 迭代器是fast-fail，但是迭代器的快速失败行为不能得到保证。 运行时间：在get，set，size等操作中，都是以常数时间运行，而add操作需要O(n)时间运行。 ArrayList的定义1public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList：支持泛型的存储模式。 extends AbstractList：继承于AbstractList，继承了其中的方法，方便操作。 implements List：实现了List接口，与继承AbstractList作用相同，实现该接口提供的方法，方便了实现。但是据开发这个collection 的作者Josh说：这其实是一个mistake，因为他写这代码的时候觉得这个会有用处，但是其实并没什么用，但因为没什么影响，就一直留到了现在。 implements RandomAccess：实现了RandomAccess接口，表明支持固定时间的快速随机访问，这也是其在get和set方法时已固定时间运行的原因 implements Cloneable：实现了Cloneable接口，内部可以调用clone()方法来返回实例的浅拷贝(shallow copy)。 implements Serializable：实现了Serializable接口，表明该类时可以序列化的。 静态全局变量1234567891011121314151617181920212223242526272829303132333435363738394041/** * 默认的初始容量 */ private static final int DEFAULT_CAPACITY = 10; /** * 用于空实例的共享空数组实例。 * 也就是说当传入的指定容量为0的时候建立数组。 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * 共享空数组实例，用于默认大小的空实例。 * 我们将其与EMPTY_ELEMENTDATA区分开来，以了解添加第一个元素时应该膨胀多少。 * 当无指定的容量传入时，返回的数组。其与EMPTY_ELEMENTDATA的区别在于： * EMPTY_ELEMENTDATA是当传入的指定容量为时候返回的 * DEFAULTCAPACITY_EMPTY_ELEMENTDATA是为传入指定容量参数时候返回的。 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 存储ArrayList元素的数组缓冲区。 * ArrayList的容量是这个数组缓冲区的长度。 * 当添加第一个元素时，任何带有elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA的空ArrayList都将扩展为DEFAULT_CAPACITY。 * 也就是底层用来存储元素的数组 */ transient Object[] elementData; // 非私有以简化嵌套类访问,这里是用来为subList方法使用的。 /** * ArrayList的大小(它包含的元素的数量)。 * ArrayList中实际包含的元素的数量 * * @serial */ private int size; /** * 最大可分配的数组大小，减去8是为了一些vm在数组中保留一些头信息。 * 试图分配更大的数组可能会导致OutOfMemoryError:请求的数组大小超过VM限制 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 构造方法指定初始容量12345678910111213141516171819202122232425/** * 构造具有指定初始容量的空列表。 * * @param initialCapacity 列表的初始容量 * @throws IllegalArgumentException 如果指定初始容量是负的 */ public ArrayList(int initialCapacity) &#123; /** * 如果指定的初始容量大于零，则创建一个指定初始容量大小的数组 */ if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; /** * 如果指定的初始等于零，则使用空数组EMPTY_ELEMENTDATA */ this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; /** * 如果指定的初始为负数，抛出异常 */ throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; 如果传入的指定初始容量大于零，那就创建一个指定初始容量大小的数组用来存放数据 如果指定的初始等于零，则使用静态全局变量中的空数组EMPTY_ELEMENTDATA 如果指定的初始为负数，抛出异常 无指定初始容量1234567 /** * 当无指定初始容量参数时，使用默认容量，构造一个初始容量为10的空列表。 * 但是其实在初始化后，此时的数组容量为0，当第一次存入数据时，才对这个空数组进行扩容，变为长度为10的数组 */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 传入集合初始化123456789101112131415161718192021222324/** * 构造包含指定集合的元素的列表，按集合的迭代器返回元素的顺序排列。 * * @param c 要将其元素放入此列表的集合 * @throws NullPointerException 如果指定的集合为空 */public ArrayList(Collection&lt;? extends E&gt; c) &#123; /** * 把传入的集合转化为数组 */ elementData = c.toArray(); /** * 判断传入的集合是否为空，如果为空则初始化为EMPTY_ELEMENTDATA数组，也就是等于指定初始容量为0时的情况 */ if ((size = elementData.length) != 0) &#123; // 为了防止传入集合转型后的数组的类型不是Object类型，所以在这里进行验证 // 如果不是Object类型，则使用Arrays.copyOf()的方法重新拷贝成Object[].class类型 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 用空数组替换。 this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 核心方法trimToSize 方法123456789101112131415161718192021/** * 修改此ArrayList实例的容量成为列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */public void trimToSize() &#123; /** * 因为是对结构进行了修改，所以modCount加一次 */ modCount++; /** * 如果当前数组中的元素数量小于数组长度，就对数组进行修改 */ if (size &lt; elementData.length) &#123; /** * 如果数组中的元素数量为0，则把数组变为EMPTY_ELEMENTDATA * 如果数组中的元素数量不为0，则把当前数组中的所有元素拷贝到一个新的数组，数组长度为元素的数量 */ elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; 该方法用于回收多余的内存。也就是说一旦我们确定集合不在添加多余的元素之后，调用 trimToSize() 方法会将实现集合的数组大小刚好调整为集合元素的大小。注意：该方法会花时间来复制数组元素，所以应该在确定不会添加元素之后在调用。 ensureCapacity 方法12345678910111213141516171819/** * 如果需要，增加此 ArrayList实例的容量，以确保它至少能够容纳最小容量参数指定的元素数。 * * @param minCapacity 所需的最小容量 */public void ensureCapacity(int minCapacity) &#123; /** * 先判断是否满足增加容量的条件： * 1.新的容量大于当前数组的长度，不然没有必要扩容 * 2.数组中有数据，或者数组中没有数据并且新的容量大于默认的容量长度 * 满足上面的两个条件后，modCount加一，然后调用grow方法进行数组的扩容和复制 */ if (minCapacity &gt; elementData.length &amp;&amp; !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA &amp;&amp; minCapacity &lt;= DEFAULT_CAPACITY)) &#123; modCount++; grow(minCapacity); &#125;&#125; grow 方法1234567891011121314151617/** * 增加容量，以确保它至少可以容纳由最小容量参数指定的元素数目。 * * @param minCapacity 所需的最小容量 * @throws OutOfMemoryError 如果minCapacity小于零 */private Object[] grow(int minCapacity) &#123; /** * 使用newCapacity方法获得新的合适的容量大小，因为minCapacity不一定时最合适的扩容容量 */ return elementData = Arrays.copyOf(elementData, newCapacity(minCapacity));&#125;private Object[] grow() &#123; return grow(size + 1);&#125; newCapacity 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 返回至少与给定的最小容量相同大的容量。返回当前容量增加50%(如果足够的话)。 * 除非给定的最小容量大于MAX_ARRAY_SIZE，否则不会返回大于MAX_ARRAY_SIZE的容量。 * * @param minCapacity 所需的最小容量 * @throws OutOfMemoryError 如果minCapacity小于零 */private int newCapacity(int minCapacity) &#123; /** * 旧的容量是现在数组的长度 * 默认的新的容量是旧容量的1.5倍 */ int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); /** * 如果传入的要求的最小容量（newCapacity）大于等于默认的新的容量，就进入if做边界条件的判断 */ if (newCapacity - minCapacity &lt;= 0) &#123; /** * 如果当前数组是空数组，这种情况下就是数组进行了初始化，但是没有放入任何数据，还是一个空数组，所以上面得到的oldCapacity和newCapacity都是0 * 那么就取要求的最小容量和默认容量（16）二者中较大的那个进行扩容。 */ if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) return Math.max(DEFAULT_CAPACITY, minCapacity); /** * 因为上面的if判断的是 &lt;= 的情况，所以有可能传入的 minCapacity是负数 */ if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); /** * 边界没有溢出的话，就扩大为minCapacity */ return minCapacity; &#125; /** * 如果传入的要求的最小容量（newCapacity）小于默认的新的容量，就不使用传入的minCapacity * 如果默认的新的容量小于数组最大容量Integer.MAX_VALUE-8，那么就使用它，也就是数组扩容1.5倍 * 但是如果大于数组最大容量Integer.MAX_VALUE-8，就尝试使用minCapacity，进入hugeCapacity函数判断 */ return (newCapacity - MAX_ARRAY_SIZE &lt;= 0) ? newCapacity : hugeCapacity(minCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // 溢出 throw new OutOfMemoryError(); /** * 如果newCapacity大于数组最大容量Integer.MAX_VALUE-8，但是minCapacity没有，就使用Integer.MAX_VALUE-8 * 但是如果newCapacity和minCapacity都大于了Integer.MAX_VALUE-8的话，就把数组扩容为Integer.MAX_VALUE */ return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 总结来说，对于数组容量扩容过程如下： 先确定三个变量：传入的所需的最小容量（minCapacity），旧容量（oldCapacity）也就是当前现在数组的长度，默认的新的容量（newCapacity）是旧容量的1.5倍。 对比minCapacity和newCapacity，如果对比minCapacity大于等于（&gt;=）newCapacity,那么进入3，否则进入5。 如果elementData是只进行初始化，但是还没有存入数据的数组，那么它的长度肯定是0，所以这种情况下上面得到的oldCapacity和newCapacity是0，因此取默认初始容量（16）和minCapacity中的较大值，作为扩容后的容量。否则进入4。 判断如果传入的minCapacity是负数，那么抛出异常。否则将其作为扩容后的容量。 如果newCapacity小于等于MAX_ARRAY_SIZE（Integer.MAX_VALUE-8），那么newCapacity就是扩容大小，也就是扩容1.5倍。否则进行6。 如果newCapacity大于minCapacity，但是minCapacity其实是负数，那么直接抛出异常。否则再次判断minCapacity与MAX_ARRAY_SIZE的大小关系，如果minCapacity也大于MAX_ARRAY_SIZE，那么newCapacity和minCapacity都大于了MAX_ARRAY_SIZE，就把数组扩容为Integer.MAX_VALUE。否则进行7。 否则就只有newCapacity大于MAX_ARRAY_SIZE，而minCapacity小于等于MAX_ARRAY_SIZE，则数组扩容为MAX_ARRAY_SIZE。 size 方法12345678/** * 以常数时间返回此列表中的元素数量。 * * @return 列表中元素的数量 */public int size() &#123; return size;&#125; isEmpty 方法12345678/** * 如果此列表不包含任何元素，则返回true。 * * @return &#123;@code true&#125; 如果此列表不包含任何元素 */public boolean isEmpty() &#123; return size == 0;&#125; contains 方法12345678910111213/** * 如果此列表包含指定的元素，则返回true 。 * 更正式地说，返回true当且仅当此列表包含至少一个元素e这样Objects.equals(o, e) 。 * * @param o 其在此列表中的存在性将被测试 * @return &#123;@code true&#125; 如果此列表包含指定的元素 */public boolean contains(Object o) &#123; /** * 实则调用了indexOf方法得到其下标，只需判断得到的下标是否小于零即可 */ return indexOf(o) &gt;= 0;&#125; indexOf 于 lastIndexOf 方法12345678910111213141516171819202122232425/** * 以常数时间返回此列表中指定元素的第一次出现的索引，如果此列表不包含元素，则返回-1。 * 更正式地，返回最低下标i ，使得Objects.equals(o, get(i)) ，如果没有这样的下标则返回-1。 */public int indexOf(Object o) &#123; /** * 如果要寻找的对象是null，那么就遍历数组，找第一个null的下标 */ if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; /** * 如果要寻找的对象非null，那么就遍历数组，找第一个为o的元素的下标 */ for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; /** * 如果找不到的话，就返回-1 */ return -1;&#125; 1234567891011121314151617/** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。 * 更正式地说，返回满足i这样Objects.equals(o, get(i)) ，如果没有这样的索引则返回-1。 * 搜索方法与indexOf相似，同为遍历整个数组，区别就是该方法从后向前寻找。 */public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; 该方法需要遍历整个数组，寻找对应的元素的下标，所以时间复杂度为O(N)。 clone​ 方法1234567891011121314151617181920212223/** * 返回此ArrayList实例的浅拷贝。（元素本身不被复制。） * * @return 这个 ArrayList实例的克隆 */public Object clone() &#123; try &#123; /** * 调用AbstractList的clone方法得到一个ArrayList * 然后给这个v的elementData数组复制为当前数组，同时modCount重置为0 * 返回这个ArrayList。 */ ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; /** * 这不应该发生，因为我们是可克隆的 */ throw new InternalError(e); &#125;&#125; 该方法只返回此ArrayList实例的浅拷贝，元素本身不被复制。 toArray 方法123456789101112131415/** * 以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 * 返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 * 因此，调用者可以自由地修改返回的数组。 * * 此方法充当基于阵列和基于集合的API之间的桥梁。 * * @return 一个包含该列表中所有元素的数组 */public Object[] toArray() &#123; /** * 使用Arrays的copyOf拷贝elementData，得到并且返回一个新的数组。 */ return Arrays.copyOf(elementData, size);&#125; 12345678910111213141516171819202122232425262728293031/** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。 * 如果列表适合指定的数组，则返回其中。 否则，将为指定数组的运行时类型和此列表的大小分配一个新数 * 如果列表符合指定的数组，则有剩余空间（即数组的列表数量较多），则紧跟在集合结束后的数组中的元素设置为null 。 * （这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） * * @param a 要存储列表的元素的数组，如果它足够大; 否则，为此目的分配相同运行时类型的新数组。 * * @return 包含列表元素的数组 * @throws ArrayStoreException 如果指定数组的运行时类型不是此列表中每个元素的运行时类型的超类型 * * @throws NullPointerException 如果指定的数组为空 */@SuppressWarnings("unchecked")public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) /** * 如果传入的数组的长度小于当前的元素数量，则创建一个新的数组a的运行时类型的数组，把elementData数组中的元素复制到该数组中。 */ return (T[]) Arrays.copyOf(elementData, size, a.getClass()); /** * 否则直接把elementData数组中的元素复制到该数组中。 */ System.arraycopy(elementData, 0, a, 0, size); /** * 如果传入数组长度大于元素数量，那么就把最后一个元素的后面的元素设置为null。 */ if (a.length &gt; size) a[size] = null; return a;&#125; toArray 方法主要有两种方式，一种是无参方法，直接返回包含此列表中所有元素的数组；另一种是传入一个数组，然后把此列表中所有元素复制到该数组中，然后返回该数组。 get 方法123456789101112131415161718/** * 因为底层是数组，所以以常数时间返回此列表中指定位置的元素。 * * @param index 要返回的元素的索下标 * @return 该列表中指定位置的元素 * @throws IndexOutOfBoundsException 如果下标超出范围（ index &lt; 0 || index &gt;= size() ） */public E get(int index) &#123; /** * Objects.checkIndex方法调用了Preconditions.checkIndex(index, length, null)检查下标是否超出范围 * Preconditions.checkIndex() 方法判断如果index &lt; 0 || index &gt;= size()，就抛出异常，否则返回传出的index。 */ Objects.checkIndex(index, size); /** * 如果下标满足要求，返回elementData数组中对应下标处的元素。 */ return elementData(index);&#125; set 方法123456789101112131415161718192021/** * 用指定的元素替换此列表中指定位置的元素。 * * @param index 要替换的元素的下标 * @param element 要存储在指定位置的元素 * @return 该元素以前在指定的位置 * @throws IndexOutOfBoundsException 如果索引超出范围（ index &lt; 0 || index &gt;= size() ） */public E set(int index, E element) &#123; /** * 同get方法一样，先判断下表是否越界，如果越阶就抛出异常。 */ Objects.checkIndex(index, size); /** * 记录下elementData数组中指定位置处的旧元素，用于返回。 * 将elementData数组中指定位置处的元素设置为传入的元素，然后返回旧的元素 */ E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; add 方法将指定的元素追加到此列表的末尾123456789101112131415/** * 以常数时间，将指定的元素追加到此列表的末尾。 * * @param e 要附加到此列表的元素 * @return &#123;@code true&#125; (由 Collection.add(E)指定) */public boolean add(E e) &#123; /** * 因为往数组中添加元素，所以结构发生了改变，因此modCount加一 * 调用内部的add方法添加元素，add方法见下面。 */ modCount++; add(e, elementData, size); return true;&#125; 内部的add方法添加元素1234567891011121314151617/** * 这个helper方法从add(E)中分离出来，以将方法字节码大小保持在35以下(-XX:MaxInlineSize默认值)，这有助于在c1编译的循环中调用add(E)。 * */private void add(E e, Object[] elementData, int s) &#123; /** * 先判断数组中的元素数量是否达到了数组长度 * 如果达到，则对数组进行扩容，扩容大小是原数组长度的1.5倍 */ if (s == elementData.length) elementData = grow(); /** * 然后将传入的元素添加到数组尾部，元素数量加一 */ elementData[s] = e; size = s + 1;&#125; 在指定位置插入指定的元素12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 以O(N)的时间，在此列表中的指定位置插入指定的元素。 * 将当前位于该位置的元素（如果有）和任何后续元素（向其索引添加一个）移动。 * * @param index 要在其中插入指定元素的下标 * @param element 要插入的元素 * @throws IndexOutOfBoundsException 如果索引超出范围（ index &lt; 0 || index &gt; size() ） */public void add(int index, E element) &#123; /** * rangeCheckForAdd方法见下面； * 同样把数组修改次数加一； */ rangeCheckForAdd(index); modCount++; final int s; Object[] elementData; /** * 如果数组中的元素数量是否达到了数组长度，对数组进行扩容，扩容大小是原数组长度的1.5倍 */ if ((s = size) == (elementData = this.elementData).length) elementData = grow(); /** * 然后将该index位置的元素和它后面的所有元素后移一位 * 把index的位置空出来，然后将其赋值为传入的元素 * 元素数量加一。 */ System.arraycopy(elementData, index, elementData, index + 1, s - index); elementData[index] = element; size = s + 1;&#125;/** * 由add和addAll使用的rangeCheck的一个版本。同为对下标范围的判断，本质与之前的checkIndex方法没什么区别。 * 只是自己自定义了抛出异常的语句而已 */private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; 总结来说，如果在指定位置插入指定的元素，因为要移动指定位置后面的所有元素，那么O(N)的时间；如果将指定的元素追加到此列表的末尾，那么仅花费常数的时间，但是如果数组需要扩容的话，将花费时间对数组进行扩容，所以尽量在初始化该List时就指定好容量大小。 remove 方法删除指定位置的元素12345678910111213141516171819202122232425/** * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。 * * @param index 要删除的元素的下标 * @return 从列表中删除的元素 * @throws IndexOutOfBoundsException 如果索引超出范围（ index &lt; 0 || index &gt;= size() ） */public E remove(int index) &#123; /** * 依旧先对下标范围进行检查 */ Objects.checkIndex(index, size); final Object[] es = elementData; /** * 把旧的元素暂存下来，调用fastRemove方法把指定位置的元素删除，等删除后返回。 */ @SuppressWarnings("unchecked") E oldValue = (E) es[index]; /** * fastRemove方法见下面 */ fastRemove(es, index); return oldValue;&#125; 删除第一个出现的指定元素12345678910111213141516171819202122232425262728293031323334/** * 从列表中删除第一个出现的指定元素（如果存在）。 * 如果列表不包含该元素，则它不会更改。 * 更正式地，删除具有最低索引i的元素，使得Objects.equals(o, get(i)) （如果这样的元素存在）。 * 如果此列表包含指定的元素（或等效地，如果此列表作为调用的结果而更改），则返回true 。 * * @param o 要从此列表中删除的元素（如果存在） * @return &#123;@code true&#125; 如果此列表包含指定的元素 */public boolean remove(Object o) &#123; final Object[] es = elementData; final int size = this.size; int i = 0; found: &#123; /** * 遍历整个数组，查找指定元素o的下标，如果数组中不存在该元素，就直接返回false */ if (o == null) &#123; for (; i &lt; size; i++) if (es[i] == null) break found; &#125; else &#123; for (; i &lt; size; i++) if (o.equals(es[i])) break found; &#125; return false; &#125; /** * 找到该元素的下标后，调用fastRemove方法进行删除。 */ fastRemove(es, i); return true;&#125; fastRemove 方法12345678910111213141516171819/** * 私有的remove方法，该方法跳过边界检查，并且不返回已删除的值。 */private void fastRemove(Object[] es, int i) &#123; /** * 数组修改次数加一 */ modCount++; final int newSize; /** * 将指定元素第一次出现的下标后面的元素全部左移一位，等于将指定元素覆盖掉 */ if ((newSize = size - 1) &gt; i) System.arraycopy(es, i + 1, es, i, newSize - i); /** * 然后将最后那个空出来的元素变赋值为null，同时size减小1 */ es[size = newSize] = null;&#125; clear 方法123456789101112131415/** * 从列表中删除所有元素。 此呼叫返回后，列表将为空。 */public void clear() &#123; /** * 数组修改次数加一 */ modCount++; final Object[] es = elementData; /** * 遍历整个数组，把所有下标置为null，同时size设置为0 */ for (int to = size, i = size = 0; i &lt; to; i++) es[i] = null;&#125; addAll 方法将指定集合中的所有元素追加到列表的末尾123456789101112131415161718192021222324252627282930313233343536373839/** * 按指定集合的Iterator返回的顺序 。 * 如果在操作进行中修改了指定的集合，则此操作的行为是不确定的。（这意味着如果指定的集合是此列表，则此调用的行为是不确定的，并且此列表是非空的。） * * @param c 包含要添加到此列表的元素的集合 * @return &#123;@code true&#125; 如果此列表因调用而更改 * @throws NullPointerException 如果指定的集合为空 */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; /** * 把传入的集合转化为数组，方便进行拷贝，同时修改次数加一 */ Object[] a = c.toArray(); modCount++; /** * 如果传入的集合中没有元素，那么此列表没有更改，因此返回false */ int numNew = a.length; if (numNew == 0) return false; Object[] elementData; final int s; /** * elementData.length- size 得到数组剩余的空闲空间， * 如果传入的集合长度numNew大于数组剩余的空闲空间，因此当前数组放不下传入的元素，所以要对数组进行扩容 * 扩容的后的大小最小值为：当前元素数量加将要添加的元素数量 */ if (numNew &gt; (elementData = this.elementData).length - (s = size)) elementData = grow(s + numNew); /** * 将传入的集合元素数组拷贝到列表数组的后面 */ System.arraycopy(a, 0, elementData, s, numNew); /** * 元素数量加上传入的元素数量 */ size = s + numNew; return true;&#125; 从指定的位置开始，将指定集合中的所有元素插入到此列表中。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 * 将当前位于该位置（如果有的话）的元素和随后的任何元素移动到右边（增加其索引）。 * 新元素将按照指定集合的迭代器返回的顺序显示在列表中。 * * @param index 从中指定集合插入第一个元素的索引 * @param c 包含要添加到此列表的元素的集合 * @return &#123;@code true&#125; 如果此列表因呼叫而更改 * @throws IndexOutOfBoundsException 如果索引超出范围（ index &lt; 0 || index &gt; size() ） * @throws NullPointerException 如果指定的集合为空 */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; /** * 使用自定义的方法对下标是否越界进行检查 */ rangeCheckForAdd(index); /** * 将传入的集合转化为数组，方便拷贝 * 同时修改次数加一 */ Object[] a = c.toArray(); modCount++; /** * 如果传入的集合中没有元素，那么此列表没有更改，因此返回false */ int numNew = a.length; if (numNew == 0) return false; Object[] elementData; final int s; /** * elementData.length- size 得到数组剩余的空闲空间， * 如果传入的集合长度numNew大于数组剩余的空闲空间，因此当前数组放不下传入的元素，所以要对数组进行扩容 * 扩容的后的大小最小值为：当前元素数量加将要添加的元素数量 */ if (numNew &gt; (elementData = this.elementData).length - (s = size)) elementData = grow(s + numNew); /** * s - index 计算得到需要向右移动的元素的长度 * 然后将其向右移动该长度 */ int numMoved = s - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); /** * 把传入的集合中的元素拷贝到指定的位置，也就是上面数组向右移动后空出来的位置 */ System.arraycopy(a, 0, elementData, index, numNew); /** * 元素数量加上传入的集合中的元素数量 */ size = s + numNew; return true; &#125; removeAll 与 retainAll 方法removeAll 方法1234567891011121314/** * 从此列表中删除指定集合中包含的所有元素。 * * @param c 包含要从此列表中删除的元素的集合 * @return &#123;@code true&#125; 如果此列表因调用而更改 * @throws ClassCastException 如果此列表的元素的类与指定的集合不兼容（ 可选 ） * @throws NullPointerException 如果此列表包含空元素，并且指定的集合不允许空元素（ 可选 ），或者如果指定的集合为空 */public boolean removeAll(Collection&lt;?&gt; c) &#123; /** * batchRemove 方法见下面 */ return batchRemove(c, false, 0, size);&#125; retainAll 方法12345678910111213/** * 仅保留此列表中包含在指定集合中的元素。 * 换句话说，从此列表中删除其中不包含在指定集合中的所有元素。 * 本质就是求交集。 * * @param c 包含要保留在此列表中的元素的集合 * @return &#123;@code true&#125; 如果此列表因调用而更改 * @throws ClassCastException 如果此列表的元素的类与指定的集合不兼容（ 可选 ） * @throws NullPointerException 如果此列表包含空元素，并且指定的集合不允许空元素（ 可选 ），或者如果指定的集合为空 */public boolean retainAll(Collection&lt;?&gt; c) &#123; return batchRemove(c, true, 0, size);&#125; batchRemove 方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 对比removeAll和retainAll方法，同样都是调用了batchRemove方法，唯一的区别就是传入的complement参数 * removeAll的参数是false，而retainAll方法传入的是true，所导致的结果则截然不同，所以这个complement是决定结果的关键 */private boolean batchRemove(Collection&lt;?&gt; c, boolean complement, final int from, final int end) &#123; /** * 该方法判断传入的集合c是否为null，如果是null则抛出异常，代码见下方 */ Objects.requireNonNull(c); final Object[] es = elementData; int r; /** * 从头开始遍历数组，它的作用就是找到数组中第一个在集合c包含或者不包含的元素的位置，具体看下面 */ for (r = from;; r++) &#123; /** * 如果r走到了最后依旧没找到任何一个集合c中包含或者不包含的元素 * 那么数组将不会发生任何变化，返回false */ if (r == end) return false; /** * 如果complement是false，那么在找到数组中第一个存在于集合c中的元素时，结束循环 * 如果complement是true，那么在找到数组中第一个不存在于集合c中的元素时，结束循环 */ if (c.contains(es[r]) != complement) break; &#125; /** * 看到w和r，顾名思义，w是write，r是read，也就是写和读，具体作用看下面就知道了 * 这里把r赋给了w，r加一 */ int w = r++; try &#123; for (Object e; r &lt; end; r++) /** * 从上一次循环中，扎到数组中第一个存在/不存在于集合c中的元素的下标开始遍历 * * 如果complement是false，那么在找到数组中一个不存在于集合c中的元素时，把他覆盖到刚刚找到的第一个存在于集合c中的元素的位置处 * 这里可能难以理解一点，可以这样想： * 因为complement是false的情况是删除重复的元素嘛，所以用数组后面不重复的元素覆盖前面的元素，以此代替了删除。 * * 同样如果complement是true，那么在找到数组中一个存在于集合c中的元素时，把他覆盖到刚刚找到的第一个不存在于集合c中的元素的位置处 */ if (c.contains(e = es[r]) == complement) es[w++] = e; &#125; catch (Throwable ex) &#123; /** * 即使c.contains()抛出异常，也可以保持与AbstractCollection的兼容性 * 将已经覆盖的元素后面重复出来的元素删除掉 */ System.arraycopy(es, r, es, w, end - r); w += end - r; throw ex; &#125; finally &#123; /** * 修改此处对应增加改变的数量 */ modCount += end - w; shiftTailOverGap(es, w, end); &#125; return true;&#125; public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj; &#125; /**通过以下元素向下滑动，消除从lo到hi的间隔。 */ private void shiftTailOverGap(Object[] es, int lo, int hi) &#123; System.arraycopy(es, hi, es, lo, size - hi); for (int to = size, i = (size -= hi - lo); i &lt; to; i++) es[i] = null; &#125; 这里总结一下removeAll，retainAll和addAll方法之间的关系吧： removeAll 方法就是把存在于指定的集合中的元素全部删除掉，也就是求补集。 retainAll 方法就是把不存在于指定的集合中的元素全部删除掉，也就是求交集。 addAll 方法就把不存在于指定的集合中的元素全部添加到列表中，也就是求并集。 subList 方法1234567891011121314151617181920/** * 返回指定的fromIndex （含）和toIndex之间的列表部分的视图。 （如果fromIndex和toIndex相等，返回的列表为空。） * 返回的列表由此列表支持，因此返回列表中的非结构更改将反映在此列表中，反之亦然。 返回的列表支持所有可选列表操作。 * 该方法消除了对显式范围操作（对于数组通常存在的排序）的需要。 * 任何期望列表的操作都可以通过传递一个子列表视图而不是整个列表来用作范围操作。 例如，以下成语从列表中移除了一系列元素： list.subList(from, to).clear(); * 可以为indexOf(Object)和lastIndexOf(Object)构造类似的成语，并且可以将Collections类中的所有算法应用于子列表。 * 如果支持列表（即，此列表）以除了通过返回的列表之外的任何方式进行结构修改 ，则此方法返回的列表的语义将变为不正确。 * （结构修改是那些改变此列表的大小，或以其他方式扰乱它，使得正在进行的迭代可能产生不正确的结果）。 * * 简单的来说，就是返回整个列表中，指定范围那部分的列表的视图。 * 但是！！如果对返回的这部分列表进行修改，那么同时原列表的对应位置也会发生修改 * 所以本质就是返回了一部分引用而已。 * * @throws IndexOutOfBoundsException 如果端点索引值超出范围 (fromIndex &lt; 0 || toIndex &gt; size) * @throws IllegalArgumentException 如果端点索引不正确 (fromIndex &gt; toIndex) */public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; subListRangeCheck(fromIndex, toIndex, size); return new SubList&lt;&gt;(this, fromIndex, toIndex);&#125; 所以总结来说，尽量不要使用subList方法，如果要使用的话，一定要注意下面几点使用方法： 千万不要再对原 List 进行任何改动的操作(例如: 增删改), 查询和遍历倒是可以. 因为如果对原 List 进行了改动, 那么后续只要是涉及到子 List 的操作就一定会出问题. 而至于会出现什么问题呢? 具体来说就是:(1) 如果是对原 List 进行修改 (即: 调用 set() 方法) 而不是增删, 那么子 List 的元素也可能会被修改 (这种情况下不会抛出并发修改异常).(2) 如果是对原 List 进行增删, 那么此后只要操作了子 List , 就一定会抛出并发修改异常. 千万不要直接对子 List 进行任何改动的操作(例如: 增删改), 但是查询和间接改动倒是可以. 不要对子 List 进行直接改动, 是因为如果在对子 List 进行直接改动之前, 原 List 已经被改动过, 那么此后在对子 List 进行直接改动的时候就会抛出并发修改异常. 如果要进行操作，则使用例如：List subList = new ArrayList&lt;&gt;(list.subList(2, list.size())); 的方法，把分割出来的数组转化为一个新的列表，在新的列表基础上操作就不会对原列表产生任何影响。 补充考虑一点：elementData设置成了transient，那ArrayList是怎么把元素序列化的呢？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // 防止序列化期间有修改 int expectedModCount = modCount; // 写出非transient非static属性（会写出size属性） s.defaultWriteObject(); // 写出元素个数 s.writeInt(size); // 依次写出元素 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; // 如果有修改，抛出异常 if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // 声明为空数组 elementData = EMPTY_ELEMENTDATA; // 读入非transient非static属性（会读取size属性） s.defaultReadObject(); // 读入元素个数，没什么用，只是因为写出的时候写了size属性，读的时候也要按顺序来读 s.readInt(); if (size &gt; 0) &#123; // 计算容量 int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); // 检查是否需要扩容 ensureCapacityInternal(size); Object[] a = elementData; // 依次读取元素到数组中 for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; 查看writeObject()方法可知，先调用s.defaultWriteObject()方法，再把size写入到流中，再把元素一个一个的写入到流中。 一般地，只要实现了Serializable接口即可自动序列化，writeObject()和readObject()是为了自己控制序列化的方式，这两个方法必须声明为private，在java.io.ObjectStreamClass#getPrivateMethod()方法中通过反射获取到writeObject()这个方法。 在ArrayList的writeObject()方法中先调用了s.defaultWriteObject()方法，这个方法是写入非static非transient的属性，在ArrayList中也就是size属性。同样地，在readObject()方法中先调用了s.defaultReadObject()方法解析出了size属性。 elementData定义为transient的优势，自己根据size序列化真实的元素，而不是根据数组的长度序列化元素，减少了空间占用。 总结 ArrayList内部使用数组存储元素，当数组长度不够时进行扩容，每次加一半的空间，ArrayList不会进行缩容； ArrayList支持随机访问，通过索引访问元素极快，时间复杂度为O(1)； ArrayList添加元素到尾部极快，平均时间复杂度为O(1)； ArrayList添加元素到中间比较慢，因为要搬移元素，平均时间复杂度为O(n)； ArrayList从尾部删除元素极快，时间复杂度为O(1)； ArrayList从中间删除元素比较慢，因为要搬移元素，平均时间复杂度为O(n)； ArrayList支持求并集，调用addAll(Collection&lt;? extends E&gt; c)方法即可； ArrayList支持求交集，调用retainAll(Collection&lt;? extends E&gt; c)方法即可； ArrayList支持求单向差集，调用removeAll(Collection&lt;? extends E&gt; c)方法即可；]]></content>
      <categories>
        <category>Java容器</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>容器</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码阅读]]></title>
    <url>%2Fposts%2F42557%2F</url>
    <content type="text"><![CDATA[HashMap的数据结构先介绍一点基础结构 HashMap的基础结构是由数组（Node&lt;K,V&gt;[] table）+ 链表 + 红黑树组成的，因为我对红黑树不太了解，所以就没有看后面红黑树部分的东西（1400行之后的代码基本全是在说红黑树部分的），下面就没有讲述红黑树部分的内容。数组的每个下标位置储存的是Node结点， 在Javadoc中把存放数据的table数组的每个下表称作bin（桶），数组每个下标的一开始存放的是链表，当链表长度大于等于（&gt;=）8的时候，会将链表转换为红黑树。 顶部注释： HashMap是Map接口基于哈希表的实现。这种实现提供了所有可选的Map操作，并允许key和value为null（除了HashMap是unsynchronized的和允许使用null外，HashMap和HashTable大致相同。）。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 此实现假设哈希函数在桶内适当地分布元素，为基本实现(get 和 put)提供了稳定的性能。迭代 collection 视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）成比例。如果遍历操作很重要，就不要把初始化容量initial capacity设置得太高（或将加载因子load factor设置得太低），否则会严重降低遍历的效率。 HashMap有两个影响性能的重要参数：初始化容量initial capacity、加载因子load factor。容量是哈希表中桶的数量，初始容量只是哈希表在创建时的容量。加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度。initial capacityload factor就是当前允许的最大元素数目，超过initial capacityload factor之后，HashMap就会进行rehashed操作来进行扩容，扩容后的的容量为之前的两倍。 通常，默认加载因子 (0.75) 在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap类的操作中，包括 get 和 put 操作，都反映了这一点）。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少rehash操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生rehash 操作。 如果很多映射关系要存储在 HashMap 实例中，则相对于按需执行自动的 rehash 操作以增大表的容量来说，使用足够大的初始容量创建它将使得映射关系能更有效地存储。 注意，此实现不是同步的。如果多个线程同时访问一个哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步。（结构上的修改是指添加或删除一个或多个映射关系的任何操作；仅改变与实例已经包含的键关联的值不是结构上的修改。）这一般通过对自然封装该映射的对象进行同步操作来完成。如果不存在这样的对象，则应该使用 Collections.synchronizedMap 方法来“包装”该映射。最好在创建时完成这一操作，以防止对映射进行意外的非同步访问，如下所示：Map m = Collections.synchronizedMap(new HashMap(…)); 由所有此类的“collection 视图方法”所返回的迭代器都是fail-fast 的：在迭代器创建之后，如果从结构上对映射进行修改，除非通过迭代器本身的remove方法，其他任何时间任何方式的修改，迭代器都将抛出 ConcurrentModificationException。因此，面对并发的修改，迭代器很快就会完全失败，而不冒在将来不确定的时间发生任意不确定行为的风险。 注意，迭代器的快速失败行为不能得到保证，一般来说，存在非同步的并发修改时，不可能作出任何坚决的保证。快速失败迭代器尽最大努力抛出 ConcurrentModificationException。因此，编写依赖于此异常的程序的做法是错误的，正确做法是：迭代器的快速失败行为应该仅用于检测bug。 此类是 Java Collections Framework 的成员。 从上面的内容可以总结出以下几点： 底层： HashMap是Map接口基于哈希表实现的。 是否允许null： HashMap允许key和value为null。 是否有序：HashMap不保证映射到顺序，特别是它不保证顺序恒久不变。 两个影响HashMap性能的参数： 初始化容量initial capacity、加载因子load factor。 每次扩容大小：扩容后的的容量为之前的两倍。 初始化容量对性能的影响： 不应设置的太小，容量小虽然可以节省空间，但是可能会导致频繁的扩容，扩容操作非常消耗时间；也不应该设置的太大，容量大会导致严重降低遍历的效率以及内存空间的浪费。总结来说就是：小了会增大时间开销（频繁的扩容）；大了会增大空间开销和时间开销（降低遍历效率）。 加载因子对性能的影响： 0.75是一个折中的值，加载因子过高虽然减少了空间开销，但是也增加了查询到成本；而加载因子过低会导致频繁的扩容。 是否同步： HashMap不是同步的。 迭代器： 迭代器是fast-fail，但是迭代器的快速失败行为不能得到保证。 HashMap的定义public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable HashMap&lt;K,V&gt;：HashMap是以key-value形式存储数据。 extends AbstractMap&lt;K,V&gt;： 继承于AbstractMap，大大减少了实现Map接口时需要的工作。 implements Map&lt;K,V： 实现了Map接口，提供所有可选的Map操作。 implements Cloneable：实现了Cloneable接口，内部可以调用clone()方法来返回实例的浅拷贝(shallow copy)。 implements Serializable：实现了Serializable接口，表明该类时可以序列化的。 静态全局变量1234567891011121314151617181920212223242526272829303132333435/** * 默认初始容量—必须是2的幂。 */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 也就是 16/** * 如果具有参数的任一构造函数隐式指定更高的值，则使用最大容量。 * 必须是2的幂 &lt;= 1 &lt;&lt; 30。 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 也就是 2的30次方/** * 构造函数中没有指定时使用的加载因子，即默认的加载因子。 */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * 将链表转化成红黑树的临界值。 * 当链表长度(包括下标处开始的那个结点)大于等于8时，桶中的链表被转化成红黑树。 */static final int TREEIFY_THRESHOLD = 8;/** * 将红黑树恢复成链表时的临界值。 * 当红黑树的长度小于等于6时，桶中的红黑树被转化成链表。 */static final int UNTREEIFY_THRESHOLD = 6;/** * 桶被转化成红黑树的最小容量。 * 当链表长度大于等于8，且HashMap的总体大小大于等于64时，才会将桶中的链表被转化成红黑树。 * 否则只会采取扩容的方式来减少冲突。 * 该值不能小于 4 * TREEIFY_THRESHOLD */static final int MIN_TREEIFY_CAPACITY = 64; 静态内部类 Node12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * HashMap的基本节点类型，即是HashMap底层的组成元素，也是每个桶（bin）中的链表的组成元素。 */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; /** * key的hash值 */ final int hash; final K key; V value; /** * 指向下一个Node节点的引用 */ Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 静态工具hash方法详解123456789/** * 计算key.hashCode（）并将更高位的散列扩展（XOR）降低。 */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125;i = (table.length - 1) &amp; hash; //这一步是在后面添加元素putVal()方法中进行位置的确定 主要分为三步： 取hashCode的值： key.hashCode()。调用Object. hashCode() 方法，该方法根据一定规则将与对象相关的信息，例如对象的存储地址，对象的字段等，映射成与一个32位 int 类型的值，这个数值称作为hash值。 让高位参与运算： h&gt;&gt;&gt;16 。将得到的hash值无符号右移十六位，空出来的高位补零。 取模运算： (n-1) &amp; hash 。 为了让数组元素分布均匀，把hash值对数组长度-1取余，也就是hash%n，得到在数组中保存的位置下标。 为什么要这样做的理由： 整个过程如上图所示，将原本的32位的hash值右移16位，然后与原值进行异或运算，是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。 看到这里有个疑问，为什么要做异或运算？设想一下，如果n很小，假设为16的话，那么n-1即为15（0000 0000 0000 0000 0000 0000 0000 1111），这样的值如果跟hashCode()直接做与操作，实际上只使用了哈希值的后4位。如果当哈希值的高位变化很大，低位变化很小，这样很容易造成碰撞，所以把高低位都参与到计算中，从而解决了这个问题，而且也不会有太大的开销。然后将得到的最终的hash值对数组长度-1取余，就可以得到在数组中保存的位置下标。这也是为什么要保证数组的长度总是2的n次方的理由。当数组长度length总是2的n次方时，(n - 1) &amp; hash == hash % n，但是位运算的速度更快，因此保证效率更高。 comparableClassFor方法解读1234567891011121314151617181920212223/** * 当对象x的类型为X，并且X实现了Comparable接口（比较的参数本身必须为X类本身）时 * 返回x的运行时类型，否则返回null。 * */ static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) &#123; for (Type t : ts) &#123; if ((t instanceof ParameterizedType) &amp;&amp; ((p = (ParameterizedType) t).getRawType() == Comparable.class) &amp;&amp; (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; return null; &#125; 如注释所示，传参传入一个对象，当对象x的类型为X，并且X实现了Comparable接口（比较的参数本身必须为X类本身）时，返回x的运行时类型，否则返回null。接下来分析这个方法的每行代码。 instanceof1x instanceof Comparable instanceof可以理解为是某种类型的实例。不论是运行时类型，或者是他的父类、它实现的接口、他的父类实现的接口、甚至是他父类的父类的父类实现的接口的父类的父类，总之，只要在继承链上有这个类型就可以了。 getClass()1c = x.getClass() 与instanceof相应对的是getClass()方法，无论该对象如何转型，该方法返回的只会是它的运行时类型，可以简单的理解为它的实际类型，也就是new它的时候的类型。有一种例外情况：匿名对象。当匿名对象调用该方法时，返回的是依赖它的对象的运行时类型，并且以1，2，3…的索引区分。 1234567891011121314151617181920212223public class Demo &#123; public static void main(String[] args) &#123; D d = new D(); System.out.println(new A()&#123;&#125;.getClass()); // class Demo$1 System.out.println(new B()&#123;&#125;.getClass()); // class Demo$2 System.out.println(new Comparable&lt;Object&gt;()&#123; // class Demo$3 @Override public int compareTo(Object o) &#123; return 0; &#125;&#125;.getClass()); System.out.println(d.c.getClass()); // class D$1 &#125;&#125;abstract class A&#123;&#125;abstract class B&#123;&#125;abstract class C&#123;&#125;class D&#123; C c; D()&#123; c= new C()&#123;&#125;; &#125;&#125; getGenericInterfaces()1ts = c.getGenericInterfaces() getGenericInterfaces()方法返回的是该对象的运行时类型”直接实现”的接口，这意味着: 返回的一定是接口 必然是该类型自己直接实现的接口，继承过来的不算 getGenericSuperclass()和getSuperclass()这两个方法虽然没有出现在上述代码中，但是也顺便说一下： getGenericSuperclass()返回的是父类的直接类型，不包括泛型参数。 getSuperclass()返回的是包括泛型参数的父类类型，但是注意，如果子类在继承父类时，没有实现（声明）父类的泛型，那么这时候子类是没有泛型参数的。 ParameterizedType 1t instanceof ParameterizedType ParameterizedType是Type接口的子接口，表示实现了泛型参数的类型。需要注意： 如果直接用Bean对象 instanceof ParameterizedType，结果都是false。 Class对象不能 instanceof ParameterizedType，编译会报错。 只有用Type对象 instanceof ParameterizedType ，才能得到想要的比较结果。可以理解为：一个Bean类不会是ParameterizedType，只有代表这个Bean类的类型（Type）才有可能是ParameterizedType。 实现泛型参数，必须给泛型传入参数，例如：class Child2&lt;A,B&gt; extends Super&lt;A,B&gt;{} ;只声明泛型而不实现,例如：class Child3&lt;A,B&gt; extends Super{} , 对比结果为false。 getRawType()1((p = (ParameterizedType) t).getRawType() 该方法返回实现了这个类型的类或者接口，即去掉了泛型参数部分的类型对象。 getActualTypeArguments()1as = p.getActualTypeArguments() 该方法与getRawType()相对应，以数组形式返回泛型的参数列表。 当参数是真实类型时，打印的是全类名 当参数是另一个新声明的泛型参数时，打印的是代表该泛型类型的符号。 所以总结comparableClassFor(Object x)方法的实现为： 123456789101112131415161718static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; // 判断是否实现了Comparable接口 Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) return c; // 如果是String类型，直接返回String.class if ((ts = c.getGenericInterfaces()) != null) &#123; // 判断是否有直接实现的接口 for (int i = 0; i &lt; ts.length; ++i) &#123; // 遍历直接实现的接口 if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; // 该接口实现了泛型 ((p = (ParameterizedType)t).getRawType() == // 获取接口不带参数部分的类型对象 Comparable.class) &amp;&amp; // 该类型是Comparable (as = p.getActualTypeArguments()) != null &amp;&amp; // 获取泛型参数数组 as.length == 1 &amp;&amp; as[0] == c) // 只有一个泛型参数，且该实现类型是该类型本身 return c; // 返回该类型 &#125; &#125; &#125; return null; &#125; compareComparables 方法1234567891011/** * Returns k.compareTo(x) if x matches kc (k's screened comparable * class), else 0. * 如果x的类型是kc，返回 k.compareTo(x) 的比较结果 * 如果x为空，或者类型不是kc，返回0 */@SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) // for cast to Comparablestatic int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x));&#125; tableSizeFor 方法12345678910111213/** * Returns a power of two size for the given target capacity. * 返回给定数值的比第一个比它大的2的幂次方的数 */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 该方法是为了在构造函数中，把传入的指定容量转化为2的幂次方的整数，保证HashMap的容量为2的幂次方。 字段1234567891011121314151617181920212223242526272829303132333435363738394041/** * table数组，存放HashMap的所有元素的容器 * 在第一次使用的时候初始化，并且可以根据需要调整大小 * 当分配时，长度总是为2的幂次方 * 在某些操作中容忍长度为零，以允许当前不需要的引导机制 */transient Node&lt;K,V&gt;[] table;/** * 保存缓存的 entrySet * AbstractMap字段用于keySet（）和values（） */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;/** * HashMap中的包含的键值对数量 */transient int size;/** * 该HashMap经过结构修改的次数 * 结构修改指的是更改HashMap中的键值对数量或者以其他方式修改其内部结构（例如：rehash） * 该字段用于在迭代器中的快速失败（fail-fast），抛出 ConcurrentModificationException 的异常 * 因为HashMap时线程不安全的容器，所以当A线程遍历时HashMap时，还没有遍历到的部分，被线程B修改，如删除 * 那么当线程A遍历到被删除的地方时就会抛出该异常 */transient int modCount;/** * 下一个要调整HashMap大小的值，容量乘加载因子(capacity * load factor). * 因为当大小超过这个值时，哈希碰撞的概率会大大增加，所以达到该值时，对HashMap扩容 * @serial */int threshold;/** * 哈希表的加载因子 * 默认为 0.75f * @serial */final float loadFactor; 核心方法构造方法指定初始化容量和加载因子12345678910111213141516171819202122 /** * 构造具有指定初始容量和加载因子的空HashMap。 * * @param initialCapacity 初始容量 * @param loadFactor 加载因子 * @throws IllegalArgumentException 如果初始容量为负或负载因子为非正时，抛出该异常 * */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity);//当指定初始容量超过最大容量（2的30次方）时，把其值设置为最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor;//将传入指定容量转换为最近的2的整数次方 this.threshold = tableSizeFor(initialCapacity); &#125; 指定初始化容量1234567891011 /** * 构造一个具有指定初始容量和默认加载因子(0.75)的空HashMap。 * * * @param initialCapacity 初始容量 * @throws IllegalArgumentException 如果初始容量为负时，抛出该异常 */ public HashMap(int initialCapacity) &#123;//调用指定初始化容量和加载因子的构造方法，加载因子为默认（0.75） this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; 默认的初始化容量和加载因子123456/** * 构造一个具有默认初始容量(16)和默认负载因子(0.75)的空HashMap。 */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // 所有其他字段都默认&#125; 使用与指定映射相同的映射123456789101112 /** * 使用与指定映射相同的映射构造新的HashMap。 * HashMap是使用默认负载因子(0.75)创建的，初始容量足以容纳指定映射中的映射。 * * @param m 要在此map中放置其键值对（映射）的map * @throws NullPointerException 如果指定的映射为空抛出该异常 */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR;//putMapEntries方法见核心方法putMapEntries()章节 putMapEntries(m, false); &#125; putMapEntries方法1234567891011121314151617181920212223242526272829303132 /** * 实现了Map接口的 Map.putAll and Map 构造方法 * 其中的加载因子等参数、是默认的 * * @param m 指定map * @param 在最初构造此映射时为false，否则为true * (传递到下面的afterNodeInsertion方法，该方法请详见允许LinkedHashMap后操作的回调节)。 */final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; //如果table未初始化，对其进行初始化 if (table == null) &#123; // pre-size //使用默认的加载因子（0.75）和传入的map的大小计算出阈值（扩容的临界值） float ft = ((float)s / loadFactor) + 1.0F; //用上一步计算出的阈值与最大容量对比，如果超过最大容量，就把它赋为最大容量 int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); //如果当前默认的阈值小于t，就把当前的阈值扩容为大于t的最小的2的整数次方的整数 if (t &gt; threshold) threshold = tableSizeFor(t); &#125;//如果table已经初始化，且传入的map的大小超过阈值，就对table扩容（resize()方法请在核心方法章节查看） else if (s &gt; threshold) resize(); //做完初始化、扩容等准备工作，现在table已经可以放下传入的map的元素了，迭代map，挨个放入table中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); //putVal()方法见下面 putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; size方法12345678/** * 返回此映射中键值对的数目。 * * @return 此映射中键值映对的数目。 */public int size() &#123; return size;&#125; isEmpty方法123456789 /** * 如果此映射不包含键值映射，则返回&#123;@code true&#125;。 * * @return 如果此映射不包含键值映射，则返回&#123;@code true&#125;。 */ public boolean isEmpty() &#123;//键值对数目为零则为空 return size == 0; &#125; get方法12345678910111213141516/** *返回指定键映射到的值，如果该映射不包含键的映射，则返回null。 * * 更正式地说，如果这个映射包含从键k到值v的映射(key==null ?k==null:key.equals(k))， * 则该方法返回v;否则返回null。(最多可以有一个这样的映射。) * * * 返回值为null并不一定表示映射不包含键的映射;也有可能映射显式地将键映射为null。 * containsKey操作可用于区分这两种情况。 * @see #put(Object, Object) */public V get(Object key) &#123; Node&lt;K,V&gt; e; //getNode方法见下面 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; getNode方法123456789101112131415161718192021222324252627282930313233343536373839404142/** * 实现 Map接口的get方法 和其他相关方法 * * @param hash key的hash值 * @param key 键（key） * @return 返回节点，如果不存在的话返回null */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; /** * 1.如果table为空，那么代表HashMap没有进行初始化 * 2.如果table长度小于等于0，那么就代表HashMap中没有数据 * 3.如果根据key的hash值计算出的下标处，没有结点，那么不存在以该key为键得映射 * 满足以上三种情况得任意一种，直接返回null；只有三种情况全部满足的情况下，才进入链表/红黑树查找 */ if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //检查该下标处得第一个结点，如果符合即返回 if (first.hash == hash &amp;&amp; // 总是检查第一个结点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //头节点不合符，那么检查头结点后面的结点 if ((e = first.next) != null) &#123; //如果桶中的数据结构是红黑树，则用红黑树的方法查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; /** * 如果同桶中的数据结构是链表，从链表的第二个节点开始，遍历链表的每一个结点查找 * e.hash == hash 比较hash值是否相等 * key.equals(k) 和 (k = e.key) == key其实是一样的 * Object的equals方法内部调用的就是 == 来验证是否相等 * 此处体现出了严谨性 */ if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; get和getNode方法总结从上面的源码中可以看出，get方法可以分为三个步骤： 通过hash方法得到key的hash值（hash方法在上面有详细的解释） 将上一步得到的key的hash值和key传入getNode方法，得到该key对应的Node 如果该key对应的Node为空，则返回null，否则返回Node中的value，如果Node中的value为空，那么也返回null getNode方法步骤如下： 判断HashMap中存放数据的table的是否初始化，是否有数据（长度是否为0），根据key的hash值计算得到的该key在table中对应得下标处是否有结点；只有三种情况全部满足的情况下，才进入下标处得链表/红黑树查找，否则直接返回null 检查下标处的头节点是否匹配，匹配则返回该节点，否则检查头结点后面的结点 判断桶中存放数据的的数据结构是红黑树还是链表，如果桶中的数据结构是红黑树，则用红黑树的方法查找。 如果是链表则从链表的第二个节点开始，遍历链表的每一个结点查找，找到就返回对应的节点。 如果红黑树或链表的遍历中都没有找到，那么就返回null，代表不存在该节点。 containsKey方法12345678910/** * 如果此映射包含特定键的映射，则返回true。 * 否则返回false。 * * @param key 要测试在此映射中存在的key * @return &#123;@code true&#125; 如果此映射包含指定的key */public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null;&#125; 该方法其实本质调用了getNode的方法，判断是否存在以key的键的结点，如过Node存在则返回true，否则返回false。 put方法1234567891011/** * 将指定参数key和指定参数value插入map中，如果key已经存在，那就替换key对应的value * * @param key 指定key * @param value 指定value * @return 如果value被替换，则返回旧的value，否则返回null。当然，可能key对应的value就是null。 */public V put(K key, V value) &#123; //putVal方法的实现就在下面 return putVal(hash(key), key, value, false, true);&#125; put方法可以分为三个步骤： 通过hash方法获取到传入的key的hash值（hash方法在上面有详细的解释） 通过putVal方法放入map中 返回putVal方法的结果 putVal方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * 实现了 Map接口的 put和 相关方法。 * * @param hash key的hash值 * @param key 键 * @param value 要放入的值 * @param onlyIfAbsent 如果为true，即使指定参数key在map中已经存在，也不会替换value * @param evict 如果为false，则该表处于创建模式。 * @return 如果value被替换，则返回旧的value，否则返回null。当然，可能key对应的value就是null。 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; /** * 如果table为null，则代表table没有初始化；或者table数组的长度为0， * 这两种情况下，调用resize方法对table进行初始化， * resize方法不仅可以对table扩容，还可以对table初始化 * n用来记录table的长度 */ if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; /** * 如果通过key的hash值计算得到的下标处没有结点，那么新建一个链表结点放入 * newNode方法调用了Node的构造方法，生成了一个新的结点。 */ if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123;//下面就是产生了碰撞的情况 Node&lt;K,V&gt; e; K k; //如果第一个结点的key就与传入的key相等，那么就把这个结点记录下来，在后面覆盖 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果第一个key没有碰撞，而且桶中的结构是树，那么就调用相应的树的方法放置键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //如果第一个key没有碰撞，而且桶中的结构是链表，那么就遍历链表 for (int binCount = 0; ; ++binCount) &#123; //binCount记录了链表长度 //当遍历到链表尾部，新建节点然后插入链表尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); /** * 如果插入后的链表长度大于等于8，那就把链表转化为树 * 这里减一是为了加上头结点，因为链表是从第二个结点开始遍历的 */ if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; &#125; //如果在链表中某个结点的key就与传入的key相等，那么就把这个结点记录下来，在后面覆盖 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果发生了结点相等的情况，那么之前就记录了下来，所以e不为null，在这里进行覆盖 if (e != null) &#123; //把结点的原值记录下来，用来返回 V oldValue = e.value; //如果存在则覆盖或者旧节点的值为空，那么覆盖 if (!onlyIfAbsent || oldValue == null) e.value = value; //回调方法，文章最后会说 afterNodeAccess(e); //把旧值返回 return oldValue; &#125; &#125; //因为上面是覆盖，所以未发生结构性改变，但是如果是插入，那么久发生了结构改变，所以modCount加一 ++modCount; //如果table大小超过了阈值，那就进行扩容，扩容后面会详细讲解 if (++size &gt; threshold) resize(); ////回调方法，文章最后会说 afterNodeInsertion(evict); return null;&#125; 总结putVal方法，共有如下几个步骤： 判断table数组是否初始化，如果没有就进行初始化 根据key的hash值计算得到的下标处，如果该下标处没有节点，那么就新建一个结点放入桶中 如果该下标处已经存在节点，那么就代表发生了碰撞，开始对链表/红黑树进行遍历 如果第一个结点的key就与传入的key相等，那么就把这个结点记录下来，在后面覆盖； 如果第一个key没有碰撞，而且桶中的结构是树，那么就调用相应的树的方法放置键值对， 如果第一个key没有碰撞，而且桶中的结构是链表，那么就遍历链表 当遍历到链表尾部，新建节点然后插入链表尾部，然后判断链表长度，是否需要转化为红黑树，如果在遍历链表中发生了key相等，那么就把这个结点记录下来，在后面覆盖； 如果发生了key相等的情况，就对结点旧值覆盖，然后把旧值返回 如果没有发生key相等的情况，而是插入了新的结点，那么modCount和size都加一，判断size是否超过阈值，超过就扩容 返回null resize方法当像HashMap中不断地添加元素的时候，元素的数量就会增加，数量增大就不避免的增大了碰撞的概率。所以当元素的数量达到一个阈值的时候，就对HashMap进行扩容。当然数组是无法自动扩容的，扩容方法使用一个新的数组代替已有的容量小的数组。resize方法非常巧妙，因为每次扩容都是翻倍，保证了数组大小为2得整数次方，同时与原来计算（n-1）&amp;hash的结果相比，节点要么就在原来的位置，要么就被分配到“原位置+旧容量”这个位置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * 对table进行初始化或者大小翻倍的扩容。 * 如果为空，则按照字段阈值中包含的初始容量目标分配。 * 否则，因为我们使用的是2的幂展开，所以每个bin中的元素必须保持相同的索引，或者在新表中以2的幂偏移量移动。 * * @return 新的table数组 */ final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //记录旧的容量大小和旧的阈值 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; //定义新的容量和阈值 int newCap, newThr = 0; //如果旧的容量 &gt; 0 if (oldCap &gt; 0) &#123; //如果旧的容量 &gt; 最大容量，那么就把阈值变为最大值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //如果旧容量的二倍小于规定的最大容量，并且旧的容量大于默认容量 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //则对数组的容量和阈值进行翻倍扩容，新的容量和阈值是旧值的二倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125;//如果旧容量 = 0，而且旧临界值 &gt; 0，那么就把容量设置为旧的阈值 else if (oldThr &gt; 0) // 初始容量设置为阈值 newCap = oldThr; else &#123; // 如果旧容量 = 0，且旧阈值 = 0，表示使用默认值，容量为16，阈值为容量*加载因子 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //在当上面的条件判断中，只有oldThr &gt; 0成立时，newThr == 0 if (newThr == 0) &#123; //ft为临时阈值，使用上面得到的新的容量和默认的加载因子计算得到 float ft = (float)newCap * loadFactor; //这个阈值是否合法，如果合法，那就是真正的临界值，如果超出了最大容量，那么就是最大容量 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //把阈值变为新阈值 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) //创建一个新的数组，大小为新的容量，并且后面把旧的table中的数据全部转移到新的table中 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //把系统的table变为新的table table = newTab; //如果旧table不为空，将旧table中的元素复制到新的table中 if (oldTab != null) &#123; //遍历旧的table的每个桶 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果该桶中含有元素，那么久开始复制，先使用e复制下来 if ((e = oldTab[j]) != null) &#123; //然后把旧的桶赋为null，便于GC回收 oldTab[j] = null; //如果这个桶中只有一个结点，那么计算新的坐标后放入 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果这个桶中的数据结构为红黑树，那么就使用红黑树的方法将其拆分后复制 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 使用两个头尾对象保持顺序，是由于链表中的元素的下标在扩容后,要么是原下标+oldCap,要么不变,下面会证实 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123;//遍历链表，分别把要存放新坐标的结点和要存放旧坐标的结点放到两根链表中 next = e.next; //如果计算得到0，那么下标没有改变，使用旧的头尾对象保存 if ((e.hash &amp; oldCap) == 0) &#123; //如果链表中没有结点，就把该节点设置为头节点 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123;//否则下标改变，使用新的头尾对象保存 //如果链表中没有结点，就把该节点设置为头节点 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原下标对应的链表 if (loTail != null) &#123; // 尾部节点next设置为null，代码严谨 loTail.next = null; //下标没有改变 newTab[j] = loHead; &#125; // 新下标对应的链表 if (hiTail != null) &#123; hiTail.next = null; //新下标为就 旧的下标+新的容量 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; resize方法总结：总体可以两大部分： 首先是计算新桶数组的容量 newCap 和新阈值 newThr 将原集合的元素重新映射到新集合中细节的过程如下： remove方法12345678910111213/** * 如果存在，则从此映射中删除指定键的映射，并且返回与该键相关联的值。 * * @param key 要从映射中删除其映射的键 * @return 与key关联的值，如果没有key的映射，则为null。 * (null返回值还可以代表将null与key关联的映射。) */ public V remove(Object key) &#123; Node&lt;K,V&gt; e; //removeNode方法就在下面 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; removeNode方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 实现了 Map接口的remove方法 和其他相关方法 * * @param hash key（键）的hash值 * @param key 键 * @param value 如果matchValue为true，则value也作为确定被删除的node的条件之一，否则忽略 * @param matchValue 如果为true，则仅在键值都相等时删除 * @param movable 如果为false，删除时不会移动其他节点 * @return Node节点，如果没有，则为空 */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果table数组不为空，且数组内有元素，且根据hash值计算得到的下标处的桶里有元素，才寻找，否则直接返回null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //如果桶上第一个node的就是要删除的node，那么就把他先记录下来，在下面删除 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果第一个结点不是，并且还有后续结点，那么就在后续节点中还寻找 else if ((e = p.next) != null) &#123; //如果是红黑树，就是用红黑树的方法寻找这个结点，也记录下来 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123;//如果是链表，就从链表的第二个个节点开始遍历寻找 do &#123;//如果找到，就把这个这个结点记录下来，在下面删除 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //如果得到的node不为null且(matchValue为false||node.value和参数value匹配) if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果是红黑树，就使用红黑树的方法删除 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p)//如果第一个结点就是要删除的目标，则使用第二个结点代替第一个结点 tab[index] = node.next; else//如果要删除的目标结点在链表中，则使用下一个结点代替该结点 p.next = node.next; //结构修改记录加一，元素个数减一 ++modCount; --size; //回调函数，最后会讲 afterNodeRemoval(node); //把删除的结点返回 return node; &#125; &#125; //如果数组table为空或key映射到的桶为空，返回null。 return null; &#125; 总结removeNode方法为： 如果数组table为空或key映射到的桶为空，直接返回null。 如果key映射到的桶上第一个Node的就是要删除的Node，记录下来。 如果桶内不止一个Node，且桶内的结构为红黑树，记录key映射到的Node。 桶内的结构不为红黑树，那么桶内的结构就肯定为链表，遍历链表，找到key映射到的Node，记录下来。 如果被记录下来的Node不为null，则使用数据结构相对应的删除方法删除Node，++modCount;–size; 返回被删除的node。 clear方法1234567891011121314151617/** * 删除HashMap中的所有映射。 * 这个调用返回后HashMap将为空。 */public void clear() &#123; Node&lt;K,V&gt;[] tab; //结构修改次数+1 modCount++; //如果table不为空且其中有元素，就进行清空 if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; //元素数量设置为零 size = 0; //遍历table数组每一个桶，将桶置为null，剩下的交给让GC自动回收 for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125;&#125; containsValue方法12345678910111213141516171819202122232425/** * 如果此HashMap中将一个或多个键映射到指定的值，则返回true。 * * * @param value 值，其在此映射中的存在性将被测试 * @return 如果此映射将一个或多个键映射到指定值，则返回true，否则返回false。 * */public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; //如果table不为空且其中有元素，就进行寻找，否则直接返回false if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; //遍历table数组中每个小标出处的桶寻找 for (Node&lt;K,V&gt; e : tab) &#123; //遍历桶中的Node结点链 for (; e != null; e = e.next) &#123; //如果有值匹配，就返回true if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false;&#125; 一些其他方法keySet方法1234567891011121314151617/** * 返回此映射中所包含的键的 Set 视图。 * 该 set 受映射的支持，所以对映射的更改将反映在该 set 中，反之亦然。 * 如果在对 set 进行迭代的同时修改了映射（通过迭代器自己的 remove 操作除外），则迭代结果是不确定的。 * 该 set 支持元素的移除，通过 Iterator.remove、 Set.remove、 removeAll、 retainAll 和 clear 操作可从该映射中移除相应的映射关系。 * 它不支持 add 或 addAll 操作。 * * @return 此映射中包含的键的 set 视图 */ public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks; &#125; values方法123456789101112131415161718/** * 返回此映射所包含的值的 Collection 视图。 * 该 collection 受映射的支持，所以对映射的更改将反映在该 collection 中，反之亦然。 * 如果在对 collection 进行迭代的同时修改了映射（通过迭代器自己的 remove 操作除外），则迭代结果是不确定的。 * 该 collection 支持元素的移除， * 通过 Iterator.remove、 Collection.remove、 removeAll、 retainAll 和 clear 操作可从该映射中移除相应的映射关系。 * 它不支持 add 或 addAll 操作。 * * @return a view of the values contained in this map */public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; if (vs == null) &#123; vs = new Values(); values = vs; &#125; return vs;&#125; entrySet方法12345678910111213/** * 返回此映射所包含的映射关系的 Set 视图。 * 该 set 受映射支持，所以对映射的更改将反映在此 set 中，反之亦然。 * 如果在对 set 进行迭代的同时修改了映射（通过迭代器自己的 remove 操作，或者通过在该迭代器返回的映射项上执行 setValue 操作除外），则迭代结果是不确定的。 * 该 set 支持元素的移除，通过 Iterator.remove、 Set.remove、 removeAll、 retainAll 和 clear 操作可从该映射中移除相应的映射关系。 * 它不支持 add 或 addAll 操作。 * * @return a set view of the mappings contained in this map */public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es;&#125; clone方法1234567891011121314151617181920212223/** * 返回此HashMap实例的浅拷贝:键和值本身没有克隆。 * 浅拷贝与深拷贝的区别： * 简单的来说就是，在有指针的情况下，浅拷贝只是增加了一个指针指向已经存在的内存 * 而深拷贝就是增加一个指针并且申请一个新的内存，使这个增加的指针指向这个新的内存 * 采用深拷贝的情况下，释放内存的时候就不会出现在浅拷贝时重复释放同一内存的错误！ * * @return a shallow copy of this map */@SuppressWarnings("unchecked")@Overridepublic Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); return result;&#125; 回调方法1234// 允许LinkedHashMap后操作的回调void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; 这三个回调方法在之前方法中出现过，它们的作用就是在给LinkedHashMap时继承使用，在HashMap中没有实质的作用，所以方法体为空。LinkedHashMap 是 HashMap 的一个子类，它保留插入的顺序，如果需要输出的顺序和输入时的相同，那么就选用 LinkedHashMap。 个人总结 可以看出HashMap在扩容时的操作是很花费时间的，所以尽量在创建HashMap的时候就把容量指定，避免扩容操作，增大运行时间。 不知道有没有人想过，为什么在很多方法中，都是新建局部变量，然后把相应的数据赋给局部变量，而不是直接使用全局变量呢？例如下面这样：12345Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;tab = table;n = tab.length;first = tab[(n - 1) &amp; hash];k = first.key; 个人猜测这样做的原因是：新定义的变量在栈顶，出栈快，局部变量，用完就销毁，提高速度，也不额外占用内存。当然还有一种可能是因为HashMap不是线程安全的，所以可能因为使用全局变量的话会导致数据差异的原因，所以在每个方法里面，把这个方法开始的时候的数据保存下来，只对当前保存下来的数据进行运算，不影响其他线程和方法对数据的使用，同时也体现了高明的严谨性。 当然这只是个人猜测的结果，具体的原因也没有查到，所以这里就算是一个遗留的小问题吧。]]></content>
      <categories>
        <category>Java容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>源码</tag>
      </tags>
  </entry>
</search>
